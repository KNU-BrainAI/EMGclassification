{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8dd054",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-11T17:54:52.053001Z",
     "iopub.status.busy": "2023-10-11T17:54:52.052296Z",
     "iopub.status.idle": "2023-10-11T17:54:52.301541Z",
     "shell.execute_reply": "2023-10-11T17:54:52.299789Z"
    },
    "papermill": {
     "duration": 0.258097,
     "end_time": "2023-10-11T17:54:52.303786",
     "exception": false,
     "start_time": "2023-10-11T17:54:52.045689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/newninaprodb4/ninaprodb44test.pkl\n",
      "/kaggle/input/newninaprodb4/ninaprodb44train.pkl\n",
      "/kaggle/input/datasetfornina/ninaprodb1train.pkl\n",
      "/kaggle/input/datasetfornina/ninaprodb1test.pkl\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/3.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/5.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/4.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/7.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/0.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/6.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/3.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/5.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/4.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/7.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/0.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/6.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/33_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/21_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/24_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/23_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/11_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/25_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/11_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/20_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/23_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/27_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/32_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/30_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/16_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/8_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/1_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/1_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/18_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/6_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/9_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/19_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/31_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/26_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/8_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/20_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/4_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/21_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/9_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/5_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/3_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/25_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/10_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/30_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/15_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/22_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/19_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/35_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/31_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/32_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/5_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/34_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/36_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/27_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/2_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/35_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/12_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/13_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/15_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/14_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/33_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/14_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/6_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/16_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/3_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/12_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/7_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/28_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/22_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/4_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/7_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/29_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/26_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/34_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/18_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/29_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/28_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/10_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/13_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/17_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/2_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/17_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/24_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/36_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/README.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/17/2_raw_data_11-20_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/17/1_raw_data_11-19_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/19/2_raw_data_12-11_26.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/19/1_raw_data_12-10_26.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/22/2_raw_data_12-39_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/22/1_raw_data_12-37_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/35/1_raw_data_10-03_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/35/2_raw_data_10-05_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/23/1_raw_data_13-18_05.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/23/2_raw_data_13-19_05.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/07/1_raw_data_18-48_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/07/2_raw_data_18-50_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/10/2_raw_data_11-10_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/10/1_raw_data_11-08_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/36/1_raw_data_13-03_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/36/2_raw_data_13-04_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/05/1_raw_data_10-28_30.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/05/2_raw_data_10-29_30.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/20/2_raw_data_11-43_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/20/1_raw_data_11-41_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/06/1_raw_data_10-38_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/06/2_raw_data_10-40_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/27/2_raw_data_12-20_06.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/27/1_raw_data_12-19_06.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/02/1_raw_data_14-19_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/02/2_raw_data_14-21_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/32/2_raw_data_12-06_27.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/32/1_raw_data_12-04_27.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/25/1_raw_data_14-51_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/25/2_raw_data_14-53_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/12/1_raw_data_11-35_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/12/2_raw_data_11-36_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/04/2_raw_data_18-03_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/04/1_raw_data_18-02_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/31/2_raw_data_11-16_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/31/1_raw_data_11-15_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/34/2_raw_data_10-53_07.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/34/1_raw_data_10-51_07.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/18/1_raw_data_12-35_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/18/2_raw_data_12-37_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/28/2_raw_data_12-11_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/28/1_raw_data_12-10_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/16/1_raw_data_12-12_25.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/16/2_raw_data_12-14_25.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/13/2_raw_data_13-29_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/13/1_raw_data_13-26_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/26/2_raw_data_10-23_29.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/26/1_raw_data_10-22_29.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/08/2_raw_data_12-16_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/08/1_raw_data_12-14_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/15/2_raw_data_08-51_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/15/1_raw_data_08-49_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/09/2_raw_data_12-43_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/09/1_raw_data_12-41_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/30/1_raw_data_09-49_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/30/2_raw_data_09-50_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/14/2_raw_data_09-51_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/14/1_raw_data_09-50_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/03/2_raw_data_09-34_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/03/1_raw_data_09-32_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/21/1_raw_data_20-28_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/21/2_raw_data_20-30_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/11/2_raw_data_13-13_18.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/11/1_raw_data_13-11_18.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/01/2_raw_data_13-13_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/01/1_raw_data_13-12_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/33/2_raw_data_09-50_12.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/33/1_raw_data_09-49_12.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/29/2_raw_data_10-18_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/29/1_raw_data_10-17_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/24/2_raw_data_10-17_12.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/24/1_raw_data_10-16_12.04.16.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3985b608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:54:52.316766Z",
     "iopub.status.busy": "2023-10-11T17:54:52.315780Z",
     "iopub.status.idle": "2023-10-11T17:55:08.189476Z",
     "shell.execute_reply": "2023-10-11T17:55:08.188443Z"
    },
    "papermill": {
     "duration": 15.882439,
     "end_time": "2023-10-11T17:55:08.191841",
     "exception": false,
     "start_time": "2023-10-11T17:54:52.309402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# ... (other code) ...\n",
    "\n",
    "\n",
    "import random\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1afa5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:08.203801Z",
     "iopub.status.busy": "2023-10-11T17:55:08.203197Z",
     "iopub.status.idle": "2023-10-11T17:55:09.726620Z",
     "shell.execute_reply": "2023-10-11T17:55:09.725442Z"
    },
    "papermill": {
     "duration": 1.53176,
     "end_time": "2023-10-11T17:55:09.729107",
     "exception": false,
     "start_time": "2023-10-11T17:55:08.197347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d7785",
   "metadata": {
    "papermill": {
     "duration": 0.005141,
     "end_time": "2023-10-11T17:55:09.740438",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.735297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70bd9296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:09.752946Z",
     "iopub.status.busy": "2023-10-11T17:55:09.751907Z",
     "iopub.status.idle": "2023-10-11T17:55:09.757114Z",
     "shell.execute_reply": "2023-10-11T17:55:09.756208Z"
    },
    "papermill": {
     "duration": 0.0134,
     "end_time": "2023-10-11T17:55:09.758914",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.745514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, optimizers, Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0f1e7",
   "metadata": {
    "papermill": {
     "duration": 0.004683,
     "end_time": "2023-10-11T17:55:09.768336",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.763653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**WORKED CODE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ff6092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:09.780077Z",
     "iopub.status.busy": "2023-10-11T17:55:09.779267Z",
     "iopub.status.idle": "2023-10-11T17:55:09.785768Z",
     "shell.execute_reply": "2023-10-11T17:55:09.784864Z"
    },
    "papermill": {
     "duration": 0.014285,
     "end_time": "2023-10-11T17:55:09.787676",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.773391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd7ef31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:09.798958Z",
     "iopub.status.busy": "2023-10-11T17:55:09.798707Z",
     "iopub.status.idle": "2023-10-11T17:55:09.802510Z",
     "shell.execute_reply": "2023-10-11T17:55:09.801538Z"
    },
    "papermill": {
     "duration": 0.011744,
     "end_time": "2023-10-11T17:55:09.804353",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.792609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "method = \"default\"\n",
    "dataset_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cda394a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:09.815612Z",
     "iopub.status.busy": "2023-10-11T17:55:09.814959Z",
     "iopub.status.idle": "2023-10-11T17:55:09.821888Z",
     "shell.execute_reply": "2023-10-11T17:55:09.821062Z"
    },
    "papermill": {
     "duration": 0.01442,
     "end_time": "2023-10-11T17:55:09.823555",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.809135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dropout, Input, Conv1D, MaxPooling1D,\n",
    "    Flatten, Dense, ReLU, TimeDistributed, Reshape, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "from tensorflow.keras import regularizers, initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03e71285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:09.834819Z",
     "iopub.status.busy": "2023-10-11T17:55:09.834573Z",
     "iopub.status.idle": "2023-10-11T17:55:16.350179Z",
     "shell.execute_reply": "2023-10-11T17:55:16.349033Z"
    },
    "papermill": {
     "duration": 6.524099,
     "end_time": "2023-10-11T17:55:16.352583",
     "exception": false,
     "start_time": "2023-10-11T17:55:09.828484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "class Nina1Dataset(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(np.concatenate(self.dataframe['emg'].tolist()))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_data = self.dataframe[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_input_data = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for i, target_row in batch_data.iterrows():\n",
    "            data = target_row['emg'][:500]\n",
    "\n",
    "            # Zero-Padding\n",
    "            if len(data) < 500:\n",
    "                data = np.concatenate((data, np.zeros((500 - len(data), 10))), axis=0)\n",
    "            coeffs = pywt.wavedec(data, 'sym8')  # Using 3 decomposition levels as an example\n",
    "            coeffs[1:] = (pywt.threshold(c, value=0.5, mode='soft') for c in coeffs[1:])\n",
    "            data = pywt.waverec(coeffs, 'sym8')\n",
    "            data = self.scaler.transform(data)\n",
    "            \n",
    "            # Division data by time-segment\n",
    "            #input_data = np.transpose(data.reshape((25, 20, 10)), (0, 2, 1))\n",
    "            input_data = data.reshape((25, 20, 10))\n",
    "            label = target_row['stimulus']\n",
    "            #label = to_categorical(label)\n",
    "            batch_input_data.append(input_data)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        # Check if the batch size is smaller than the desired batch_size\n",
    "        if len(batch_data) < self.batch_size:\n",
    "            # Create a dummy batch with all elements set to zero\n",
    "            dummy_input_data = np.zeros((self.batch_size,) + input_data.shape, dtype=np.float32)\n",
    "            dummy_labels = np.zeros((self.batch_size,), dtype=np.int32)\n",
    "            dummy_input_data[:len(batch_input_data)] = np.array(batch_input_data)\n",
    "            dummy_labels[:len(batch_labels)] = np.array(batch_labels)\n",
    "            dummy_labels = to_categorical(dummy_labels,num_classes=52)  # Convert labels to one-hot encoding\n",
    "            \n",
    "            return dummy_input_data, dummy_labels\n",
    "        \n",
    "        batch_labels = to_categorical(batch_labels,num_classes=52)  # Convert labels to one-hot encoding\n",
    "        \n",
    "        return np.array(batch_input_data), np.array(batch_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "batch_size =16\n",
    "train_dir = '/kaggle/input/datasetfornina/ninaprodb1train.pkl'\n",
    "test_dir = '/kaggle/input/datasetfornina/ninaprodb1test.pkl'\n",
    "\n",
    "# Set up dataset\n",
    "\n",
    "train = pd.read_pickle(train_dir)\n",
    "eval_data = pd.read_pickle(test_dir)\n",
    "\n",
    "# Load train data\n",
    "train_data = pd.read_pickle(train_dir)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "#train_data, val_data = train_test_split(train_data, test_size=0.3, random_state=21)\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "#val_data = val_data.sample(frac=1).reset_index(drop=True)\n",
    "eval_data = eval_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create train, test and validation datasets\n",
    "train_dataset = Nina1Dataset(train_data, batch_size=batch_size)\n",
    "#val_dataset= Nina1Dataset(val_data, batch_size=batch_size)\n",
    "test_dataset= Nina1Dataset(eval_data, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4445def1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:16.364585Z",
     "iopub.status.busy": "2023-10-11T17:55:16.364273Z",
     "iopub.status.idle": "2023-10-11T17:55:21.395559Z",
     "shell.execute_reply": "2023-10-11T17:55:21.394505Z"
    },
    "papermill": {
     "duration": 5.039637,
     "end_time": "2023-10-11T17:55:21.397641",
     "exception": false,
     "start_time": "2023-10-11T17:55:16.358004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (9840, 25, 20, 10)\n",
      "y_train shape: (9840, 52)\n",
      "x_test shape: (4224, 25, 20, 10)\n",
      "y_test shape: (4224, 52)\n"
     ]
    }
   ],
   "source": [
    "# Create x_train, y_train from train_dataset\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    batch_x, batch_y = train_dataset[i]\n",
    "    x_train.extend(batch_x)\n",
    "    y_train.extend(batch_y)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Create x_test, y_test from test_dataset\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    batch_x, batch_y = test_dataset[i]\n",
    "    x_test.extend(batch_x)\n",
    "    y_test.extend(batch_y)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73928b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T17:55:21.411031Z",
     "iopub.status.busy": "2023-10-11T17:55:21.410765Z",
     "iopub.status.idle": "2023-10-11T19:33:37.539377Z",
     "shell.execute_reply": "2023-10-11T19:33:37.538341Z"
    },
    "papermill": {
     "duration": 5896.138221,
     "end_time": "2023-10-11T19:33:37.541567",
     "exception": false,
     "start_time": "2023-10-11T17:55:21.403346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 25, 64)\n",
      "11\n",
      "(None, 25, 400)\n",
      "11\n",
      "(None, 25, 400)\n",
      "11\n",
      "(None, 25, 64)\n",
      "11\n",
      "(None, 25, 400)\n",
      "11\n",
      "(None, 25, 400)\n",
      "11\n",
      "Epoch 1/200\n",
      "615/615 [==============================] - 40s 25ms/step - loss: 3.6520 - accuracy: 0.1188 - val_loss: 2.9467 - val_accuracy: 0.2206\n",
      "Epoch 2/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 2.7775 - accuracy: 0.2575 - val_loss: 2.3582 - val_accuracy: 0.3501\n",
      "Epoch 3/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 2.4405 - accuracy: 0.3285 - val_loss: 2.1898 - val_accuracy: 0.4264\n",
      "Epoch 4/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 2.1864 - accuracy: 0.3832 - val_loss: 1.8749 - val_accuracy: 0.4986\n",
      "Epoch 5/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 2.0186 - accuracy: 0.4293 - val_loss: 1.5717 - val_accuracy: 0.5405\n",
      "Epoch 6/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 1.8252 - accuracy: 0.4730 - val_loss: 1.4816 - val_accuracy: 0.5821\n",
      "Epoch 7/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 1.6769 - accuracy: 0.5079 - val_loss: 1.4091 - val_accuracy: 0.6307\n",
      "Epoch 8/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 1.5365 - accuracy: 0.5497 - val_loss: 1.2469 - val_accuracy: 0.6626\n",
      "Epoch 9/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 1.4272 - accuracy: 0.5724 - val_loss: 1.0702 - val_accuracy: 0.6863\n",
      "Epoch 10/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 1.2810 - accuracy: 0.6215 - val_loss: 0.9430 - val_accuracy: 0.7145\n",
      "Epoch 11/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 1.1767 - accuracy: 0.6423 - val_loss: 0.8987 - val_accuracy: 0.7550\n",
      "Epoch 12/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 1.0819 - accuracy: 0.6765 - val_loss: 0.9359 - val_accuracy: 0.7379\n",
      "Epoch 13/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.9821 - accuracy: 0.7039 - val_loss: 0.7899 - val_accuracy: 0.7713\n",
      "Epoch 14/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.8951 - accuracy: 0.7329 - val_loss: 0.7174 - val_accuracy: 0.7966\n",
      "Epoch 15/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.8347 - accuracy: 0.7502 - val_loss: 0.6343 - val_accuracy: 0.8217\n",
      "Epoch 16/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.7628 - accuracy: 0.7703 - val_loss: 0.6959 - val_accuracy: 0.7926\n",
      "Epoch 17/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.7114 - accuracy: 0.7859 - val_loss: 0.5994 - val_accuracy: 0.8260\n",
      "Epoch 18/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.6560 - accuracy: 0.8029 - val_loss: 0.9532 - val_accuracy: 0.8317\n",
      "Epoch 19/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.5905 - accuracy: 0.8297 - val_loss: 0.5640 - val_accuracy: 0.8430\n",
      "Epoch 20/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.5537 - accuracy: 0.8405 - val_loss: 0.6088 - val_accuracy: 0.8414\n",
      "Epoch 21/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.5308 - accuracy: 0.8439 - val_loss: 0.5033 - val_accuracy: 0.8608\n",
      "Epoch 22/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.4998 - accuracy: 0.8567 - val_loss: 0.6039 - val_accuracy: 0.8506\n",
      "Epoch 23/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.4511 - accuracy: 0.8672 - val_loss: 0.5288 - val_accuracy: 0.8539\n",
      "Epoch 24/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.4259 - accuracy: 0.8748 - val_loss: 0.4658 - val_accuracy: 0.8712\n",
      "Epoch 25/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.4078 - accuracy: 0.8824 - val_loss: 0.4649 - val_accuracy: 0.8707\n",
      "Epoch 26/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.3745 - accuracy: 0.8903 - val_loss: 0.4620 - val_accuracy: 0.8726\n",
      "Epoch 27/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.3664 - accuracy: 0.8956 - val_loss: 0.4408 - val_accuracy: 0.8812\n",
      "Epoch 28/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.3530 - accuracy: 0.9000 - val_loss: 0.4765 - val_accuracy: 0.8719\n",
      "Epoch 29/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.3264 - accuracy: 0.9049 - val_loss: 0.4300 - val_accuracy: 0.8816\n",
      "Epoch 30/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.3092 - accuracy: 0.9162 - val_loss: 0.4435 - val_accuracy: 0.8830\n",
      "Epoch 31/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2823 - accuracy: 0.9242 - val_loss: 0.4383 - val_accuracy: 0.8783\n",
      "Epoch 32/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2891 - accuracy: 0.9195 - val_loss: 0.4103 - val_accuracy: 0.8918\n",
      "Epoch 33/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2635 - accuracy: 0.9297 - val_loss: 0.4096 - val_accuracy: 0.8930\n",
      "Epoch 34/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.2772 - accuracy: 0.9217 - val_loss: 0.4203 - val_accuracy: 0.8875\n",
      "Epoch 35/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.2545 - accuracy: 0.9302 - val_loss: 0.3971 - val_accuracy: 0.8973\n",
      "Epoch 36/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2435 - accuracy: 0.9341 - val_loss: 0.4054 - val_accuracy: 0.8951\n",
      "Epoch 37/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2387 - accuracy: 0.9353 - val_loss: 0.4107 - val_accuracy: 0.8899\n",
      "Epoch 38/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.2244 - accuracy: 0.9412 - val_loss: 0.4130 - val_accuracy: 0.8932\n",
      "Epoch 39/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.2247 - accuracy: 0.9398 - val_loss: 0.4005 - val_accuracy: 0.8928\n",
      "Epoch 40/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2187 - accuracy: 0.9436 - val_loss: 0.3989 - val_accuracy: 0.8973\n",
      "Epoch 41/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2108 - accuracy: 0.9452 - val_loss: 0.3977 - val_accuracy: 0.8937\n",
      "Epoch 42/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.2048 - accuracy: 0.9480 - val_loss: 0.3914 - val_accuracy: 0.8977\n",
      "Epoch 43/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1971 - accuracy: 0.9489 - val_loss: 0.3894 - val_accuracy: 0.8982\n",
      "Epoch 44/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1868 - accuracy: 0.9551 - val_loss: 0.3890 - val_accuracy: 0.8982\n",
      "Epoch 45/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1879 - accuracy: 0.9536 - val_loss: 0.3772 - val_accuracy: 0.9027\n",
      "Epoch 46/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1857 - accuracy: 0.9558 - val_loss: 0.3785 - val_accuracy: 0.9010\n",
      "Epoch 47/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1853 - accuracy: 0.9546 - val_loss: 0.3873 - val_accuracy: 0.9022\n",
      "Epoch 48/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1789 - accuracy: 0.9544 - val_loss: 0.3863 - val_accuracy: 0.8984\n",
      "Epoch 49/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1900 - accuracy: 0.9542 - val_loss: 0.3670 - val_accuracy: 0.9053\n",
      "Epoch 50/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1787 - accuracy: 0.9551 - val_loss: 0.4039 - val_accuracy: 0.9008\n",
      "Epoch 51/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1639 - accuracy: 0.9600 - val_loss: 0.3969 - val_accuracy: 0.8958\n",
      "Epoch 52/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1709 - accuracy: 0.9599 - val_loss: 0.3766 - val_accuracy: 0.9039\n",
      "Epoch 53/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1695 - accuracy: 0.9601 - val_loss: 0.3756 - val_accuracy: 0.9039\n",
      "Epoch 54/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1709 - accuracy: 0.9608 - val_loss: 0.3892 - val_accuracy: 0.9008\n",
      "Epoch 55/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1677 - accuracy: 0.9603 - val_loss: 0.3782 - val_accuracy: 0.9020\n",
      "Epoch 56/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1583 - accuracy: 0.9632 - val_loss: 0.3977 - val_accuracy: 0.9015\n",
      "Epoch 57/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1644 - accuracy: 0.9610 - val_loss: 0.3708 - val_accuracy: 0.9032\n",
      "Epoch 58/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1690 - accuracy: 0.9569 - val_loss: 0.3695 - val_accuracy: 0.9034\n",
      "Epoch 59/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1548 - accuracy: 0.9653 - val_loss: 0.3650 - val_accuracy: 0.9065\n",
      "Epoch 60/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1492 - accuracy: 0.9648 - val_loss: 0.3712 - val_accuracy: 0.9044\n",
      "Epoch 61/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1521 - accuracy: 0.9632 - val_loss: 0.3705 - val_accuracy: 0.9039\n",
      "Epoch 62/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1513 - accuracy: 0.9652 - val_loss: 0.3848 - val_accuracy: 0.9048\n",
      "Epoch 63/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1584 - accuracy: 0.9627 - val_loss: 0.3833 - val_accuracy: 0.9051\n",
      "Epoch 64/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1513 - accuracy: 0.9639 - val_loss: 0.3929 - val_accuracy: 0.8975\n",
      "Epoch 65/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1490 - accuracy: 0.9640 - val_loss: 0.3665 - val_accuracy: 0.9065\n",
      "Epoch 66/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1540 - accuracy: 0.9612 - val_loss: 0.3696 - val_accuracy: 0.9065\n",
      "Epoch 67/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1527 - accuracy: 0.9634 - val_loss: 0.3812 - val_accuracy: 0.9044\n",
      "Epoch 68/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1404 - accuracy: 0.9698 - val_loss: 0.3781 - val_accuracy: 0.9039\n",
      "Epoch 69/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1534 - accuracy: 0.9634 - val_loss: 0.3741 - val_accuracy: 0.9051\n",
      "Epoch 70/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1497 - accuracy: 0.9646 - val_loss: 0.3717 - val_accuracy: 0.9036\n",
      "Epoch 71/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1387 - accuracy: 0.9699 - val_loss: 0.3760 - val_accuracy: 0.9074\n",
      "Epoch 72/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1477 - accuracy: 0.9645 - val_loss: 0.3756 - val_accuracy: 0.9062\n",
      "Epoch 73/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1420 - accuracy: 0.9681 - val_loss: 0.3605 - val_accuracy: 0.9093\n",
      "Epoch 74/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1493 - accuracy: 0.9662 - val_loss: 0.3614 - val_accuracy: 0.9081\n",
      "Epoch 75/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1420 - accuracy: 0.9684 - val_loss: 0.3729 - val_accuracy: 0.9084\n",
      "Epoch 76/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1425 - accuracy: 0.9696 - val_loss: 0.3680 - val_accuracy: 0.9098\n",
      "Epoch 77/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1501 - accuracy: 0.9643 - val_loss: 0.3795 - val_accuracy: 0.9039\n",
      "Epoch 78/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1354 - accuracy: 0.9701 - val_loss: 0.3703 - val_accuracy: 0.9051\n",
      "Epoch 79/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1410 - accuracy: 0.9675 - val_loss: 0.3767 - val_accuracy: 0.9060\n",
      "Epoch 80/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1411 - accuracy: 0.9703 - val_loss: 0.3880 - val_accuracy: 0.9074\n",
      "Epoch 81/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1397 - accuracy: 0.9691 - val_loss: 0.3681 - val_accuracy: 0.9074\n",
      "Epoch 82/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1446 - accuracy: 0.9661 - val_loss: 0.3630 - val_accuracy: 0.9103\n",
      "Epoch 83/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1365 - accuracy: 0.9710 - val_loss: 0.3619 - val_accuracy: 0.9074\n",
      "Epoch 84/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1396 - accuracy: 0.9695 - val_loss: 0.3576 - val_accuracy: 0.9091\n",
      "Epoch 85/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1436 - accuracy: 0.9678 - val_loss: 0.3586 - val_accuracy: 0.9107\n",
      "Epoch 86/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1376 - accuracy: 0.9694 - val_loss: 0.3663 - val_accuracy: 0.9089\n",
      "Epoch 87/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1396 - accuracy: 0.9678 - val_loss: 0.3658 - val_accuracy: 0.9096\n",
      "Epoch 88/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1382 - accuracy: 0.9699 - val_loss: 0.3629 - val_accuracy: 0.9077\n",
      "Epoch 89/200\n",
      "615/615 [==============================] - 14s 24ms/step - loss: 0.1347 - accuracy: 0.9673 - val_loss: 0.3693 - val_accuracy: 0.9072\n",
      "Epoch 90/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1350 - accuracy: 0.9706 - val_loss: 0.3654 - val_accuracy: 0.9091\n",
      "Epoch 91/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1382 - accuracy: 0.9694 - val_loss: 0.3828 - val_accuracy: 0.9044\n",
      "Epoch 92/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1405 - accuracy: 0.9680 - val_loss: 0.3507 - val_accuracy: 0.9103\n",
      "Epoch 93/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1336 - accuracy: 0.9702 - val_loss: 0.3547 - val_accuracy: 0.9103\n",
      "Epoch 94/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1384 - accuracy: 0.9687 - val_loss: 0.3655 - val_accuracy: 0.9081\n",
      "Epoch 95/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1305 - accuracy: 0.9727 - val_loss: 0.3759 - val_accuracy: 0.9051\n",
      "Epoch 96/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1434 - accuracy: 0.9678 - val_loss: 0.3719 - val_accuracy: 0.9079\n",
      "Epoch 97/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1324 - accuracy: 0.9694 - val_loss: 0.3735 - val_accuracy: 0.9079\n",
      "Epoch 98/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1325 - accuracy: 0.9729 - val_loss: 0.3629 - val_accuracy: 0.9091\n",
      "Epoch 99/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1364 - accuracy: 0.9682 - val_loss: 0.3759 - val_accuracy: 0.9077\n",
      "Epoch 100/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1367 - accuracy: 0.9710 - val_loss: 0.3576 - val_accuracy: 0.9067\n",
      "Epoch 101/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1318 - accuracy: 0.9716 - val_loss: 0.3766 - val_accuracy: 0.9048\n",
      "Epoch 102/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1316 - accuracy: 0.9711 - val_loss: 0.3702 - val_accuracy: 0.9074\n",
      "Epoch 103/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1319 - accuracy: 0.9713 - val_loss: 0.3717 - val_accuracy: 0.9060\n",
      "Epoch 104/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1353 - accuracy: 0.9695 - val_loss: 0.3629 - val_accuracy: 0.9096\n",
      "Epoch 105/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1347 - accuracy: 0.9702 - val_loss: 0.3660 - val_accuracy: 0.9086\n",
      "Epoch 106/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1389 - accuracy: 0.9693 - val_loss: 0.3590 - val_accuracy: 0.9100\n",
      "Epoch 107/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1438 - accuracy: 0.9678 - val_loss: 0.3696 - val_accuracy: 0.9079\n",
      "Epoch 108/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1438 - accuracy: 0.9670 - val_loss: 0.3741 - val_accuracy: 0.9077\n",
      "Epoch 109/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1364 - accuracy: 0.9695 - val_loss: 0.3701 - val_accuracy: 0.9070\n",
      "Epoch 110/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1382 - accuracy: 0.9697 - val_loss: 0.3691 - val_accuracy: 0.9065\n",
      "Epoch 111/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1345 - accuracy: 0.9712 - val_loss: 0.3643 - val_accuracy: 0.9081\n",
      "Epoch 112/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1376 - accuracy: 0.9690 - val_loss: 0.3619 - val_accuracy: 0.9096\n",
      "Epoch 113/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1405 - accuracy: 0.9669 - val_loss: 0.3907 - val_accuracy: 0.9025\n",
      "Epoch 114/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1374 - accuracy: 0.9679 - val_loss: 0.3776 - val_accuracy: 0.9070\n",
      "Epoch 115/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1264 - accuracy: 0.9739 - val_loss: 0.3643 - val_accuracy: 0.9081\n",
      "Epoch 116/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1349 - accuracy: 0.9678 - val_loss: 0.3729 - val_accuracy: 0.9077\n",
      "Epoch 117/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1311 - accuracy: 0.9709 - val_loss: 0.3683 - val_accuracy: 0.9077\n",
      "Epoch 118/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1329 - accuracy: 0.9712 - val_loss: 0.3668 - val_accuracy: 0.9089\n",
      "Epoch 119/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1301 - accuracy: 0.9708 - val_loss: 0.3627 - val_accuracy: 0.9081\n",
      "Epoch 120/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1292 - accuracy: 0.9720 - val_loss: 0.3659 - val_accuracy: 0.9093\n",
      "Epoch 121/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1461 - accuracy: 0.9668 - val_loss: 0.3564 - val_accuracy: 0.9110\n",
      "Epoch 122/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1375 - accuracy: 0.9696 - val_loss: 0.3551 - val_accuracy: 0.9122\n",
      "Epoch 123/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1380 - accuracy: 0.9703 - val_loss: 0.3895 - val_accuracy: 0.9020\n",
      "Epoch 124/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1376 - accuracy: 0.9676 - val_loss: 0.3692 - val_accuracy: 0.9060\n",
      "Epoch 125/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1381 - accuracy: 0.9679 - val_loss: 0.3798 - val_accuracy: 0.9065\n",
      "Epoch 126/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1355 - accuracy: 0.9699 - val_loss: 0.3608 - val_accuracy: 0.9091\n",
      "Epoch 127/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1387 - accuracy: 0.9694 - val_loss: 0.3651 - val_accuracy: 0.9072\n",
      "Epoch 128/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1375 - accuracy: 0.9683 - val_loss: 0.3764 - val_accuracy: 0.9058\n",
      "Epoch 129/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1282 - accuracy: 0.9716 - val_loss: 0.3755 - val_accuracy: 0.9065\n",
      "Epoch 130/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1356 - accuracy: 0.9690 - val_loss: 0.3523 - val_accuracy: 0.9103\n",
      "Epoch 131/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1299 - accuracy: 0.9702 - val_loss: 0.3698 - val_accuracy: 0.9089\n",
      "Epoch 132/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1386 - accuracy: 0.9668 - val_loss: 0.3580 - val_accuracy: 0.9098\n",
      "Epoch 133/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1334 - accuracy: 0.9727 - val_loss: 0.3800 - val_accuracy: 0.9070\n",
      "Epoch 134/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1326 - accuracy: 0.9720 - val_loss: 0.3482 - val_accuracy: 0.9093\n",
      "Epoch 135/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1293 - accuracy: 0.9746 - val_loss: 0.3601 - val_accuracy: 0.9096\n",
      "Epoch 136/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1372 - accuracy: 0.9711 - val_loss: 0.3625 - val_accuracy: 0.9074\n",
      "Epoch 137/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1346 - accuracy: 0.9702 - val_loss: 0.3710 - val_accuracy: 0.9065\n",
      "Epoch 138/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1376 - accuracy: 0.9678 - val_loss: 0.3730 - val_accuracy: 0.9053\n",
      "Epoch 139/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1354 - accuracy: 0.9706 - val_loss: 0.3728 - val_accuracy: 0.9074\n",
      "Epoch 140/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1313 - accuracy: 0.9696 - val_loss: 0.3582 - val_accuracy: 0.9096\n",
      "Epoch 141/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1412 - accuracy: 0.9687 - val_loss: 0.3815 - val_accuracy: 0.9051\n",
      "Epoch 142/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1362 - accuracy: 0.9707 - val_loss: 0.3801 - val_accuracy: 0.9065\n",
      "Epoch 143/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1381 - accuracy: 0.9681 - val_loss: 0.3630 - val_accuracy: 0.9098\n",
      "Epoch 144/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1358 - accuracy: 0.9690 - val_loss: 0.3639 - val_accuracy: 0.9089\n",
      "Epoch 145/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1358 - accuracy: 0.9673 - val_loss: 0.3630 - val_accuracy: 0.9081\n",
      "Epoch 146/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1338 - accuracy: 0.9702 - val_loss: 0.3630 - val_accuracy: 0.9081\n",
      "Epoch 147/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1384 - accuracy: 0.9691 - val_loss: 0.3640 - val_accuracy: 0.9084\n",
      "Epoch 148/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1352 - accuracy: 0.9707 - val_loss: 0.3707 - val_accuracy: 0.9077\n",
      "Epoch 149/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1346 - accuracy: 0.9689 - val_loss: 0.3497 - val_accuracy: 0.9098\n",
      "Epoch 150/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1366 - accuracy: 0.9696 - val_loss: 0.3598 - val_accuracy: 0.9091\n",
      "Epoch 151/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1310 - accuracy: 0.9715 - val_loss: 0.3670 - val_accuracy: 0.9105\n",
      "Epoch 152/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1379 - accuracy: 0.9686 - val_loss: 0.3623 - val_accuracy: 0.9072\n",
      "Epoch 153/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1334 - accuracy: 0.9705 - val_loss: 0.3626 - val_accuracy: 0.9089\n",
      "Epoch 154/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1309 - accuracy: 0.9716 - val_loss: 0.3563 - val_accuracy: 0.9089\n",
      "Epoch 155/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1317 - accuracy: 0.9710 - val_loss: 0.3717 - val_accuracy: 0.9065\n",
      "Epoch 156/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1375 - accuracy: 0.9684 - val_loss: 0.3562 - val_accuracy: 0.9098\n",
      "Epoch 157/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1293 - accuracy: 0.9731 - val_loss: 0.3627 - val_accuracy: 0.9081\n",
      "Epoch 158/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1351 - accuracy: 0.9700 - val_loss: 0.3639 - val_accuracy: 0.9098\n",
      "Epoch 159/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1360 - accuracy: 0.9694 - val_loss: 0.3676 - val_accuracy: 0.9091\n",
      "Epoch 160/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1401 - accuracy: 0.9684 - val_loss: 0.3697 - val_accuracy: 0.9086\n",
      "Epoch 161/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1275 - accuracy: 0.9739 - val_loss: 0.3947 - val_accuracy: 0.9060\n",
      "Epoch 162/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1367 - accuracy: 0.9702 - val_loss: 0.3667 - val_accuracy: 0.9058\n",
      "Epoch 163/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1462 - accuracy: 0.9658 - val_loss: 0.3613 - val_accuracy: 0.9084\n",
      "Epoch 164/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1360 - accuracy: 0.9696 - val_loss: 0.3703 - val_accuracy: 0.9065\n",
      "Epoch 165/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1343 - accuracy: 0.9702 - val_loss: 0.3519 - val_accuracy: 0.9103\n",
      "Epoch 166/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1345 - accuracy: 0.9688 - val_loss: 0.3687 - val_accuracy: 0.9086\n",
      "Epoch 167/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1333 - accuracy: 0.9715 - val_loss: 0.3603 - val_accuracy: 0.9091\n",
      "Epoch 168/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1331 - accuracy: 0.9710 - val_loss: 0.3698 - val_accuracy: 0.9084\n",
      "Epoch 169/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1305 - accuracy: 0.9699 - val_loss: 0.3634 - val_accuracy: 0.9086\n",
      "Epoch 170/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1316 - accuracy: 0.9710 - val_loss: 0.3597 - val_accuracy: 0.9067\n",
      "Epoch 171/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1421 - accuracy: 0.9660 - val_loss: 0.3812 - val_accuracy: 0.9051\n",
      "Epoch 172/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1402 - accuracy: 0.9673 - val_loss: 0.3749 - val_accuracy: 0.9072\n",
      "Epoch 173/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1293 - accuracy: 0.9701 - val_loss: 0.3667 - val_accuracy: 0.9079\n",
      "Epoch 174/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1359 - accuracy: 0.9682 - val_loss: 0.3777 - val_accuracy: 0.9062\n",
      "Epoch 175/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1309 - accuracy: 0.9721 - val_loss: 0.3573 - val_accuracy: 0.9093\n",
      "Epoch 176/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1378 - accuracy: 0.9707 - val_loss: 0.3653 - val_accuracy: 0.9086\n",
      "Epoch 177/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1373 - accuracy: 0.9683 - val_loss: 0.3590 - val_accuracy: 0.9086\n",
      "Epoch 178/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1397 - accuracy: 0.9674 - val_loss: 0.3806 - val_accuracy: 0.9051\n",
      "Epoch 179/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1383 - accuracy: 0.9687 - val_loss: 0.3805 - val_accuracy: 0.9072\n",
      "Epoch 180/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1292 - accuracy: 0.9705 - val_loss: 0.3714 - val_accuracy: 0.9077\n",
      "Epoch 181/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1340 - accuracy: 0.9699 - val_loss: 0.3665 - val_accuracy: 0.9062\n",
      "Epoch 182/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1379 - accuracy: 0.9688 - val_loss: 0.3991 - val_accuracy: 0.9008\n",
      "Epoch 183/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1322 - accuracy: 0.9702 - val_loss: 0.3675 - val_accuracy: 0.9077\n",
      "Epoch 184/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1370 - accuracy: 0.9710 - val_loss: 0.3598 - val_accuracy: 0.9089\n",
      "Epoch 185/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1356 - accuracy: 0.9704 - val_loss: 0.3702 - val_accuracy: 0.9072\n",
      "Epoch 186/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1387 - accuracy: 0.9701 - val_loss: 0.3817 - val_accuracy: 0.9041\n",
      "Epoch 187/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1341 - accuracy: 0.9703 - val_loss: 0.3661 - val_accuracy: 0.9086\n",
      "Epoch 188/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1323 - accuracy: 0.9706 - val_loss: 0.3531 - val_accuracy: 0.9100\n",
      "Epoch 189/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1339 - accuracy: 0.9702 - val_loss: 0.3736 - val_accuracy: 0.9081\n",
      "Epoch 190/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1361 - accuracy: 0.9699 - val_loss: 0.3710 - val_accuracy: 0.9072\n",
      "Epoch 191/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1348 - accuracy: 0.9710 - val_loss: 0.3759 - val_accuracy: 0.9060\n",
      "Epoch 192/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1395 - accuracy: 0.9684 - val_loss: 0.3776 - val_accuracy: 0.9053\n",
      "Epoch 193/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1274 - accuracy: 0.9736 - val_loss: 0.3635 - val_accuracy: 0.9084\n",
      "Epoch 194/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1348 - accuracy: 0.9689 - val_loss: 0.3580 - val_accuracy: 0.9086\n",
      "Epoch 195/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1364 - accuracy: 0.9682 - val_loss: 0.3703 - val_accuracy: 0.9072\n",
      "Epoch 196/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1327 - accuracy: 0.9704 - val_loss: 0.3571 - val_accuracy: 0.9110\n",
      "Epoch 197/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1400 - accuracy: 0.9670 - val_loss: 0.3579 - val_accuracy: 0.9081\n",
      "Epoch 198/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1291 - accuracy: 0.9720 - val_loss: 0.3654 - val_accuracy: 0.9089\n",
      "Epoch 199/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1339 - accuracy: 0.9701 - val_loss: 0.3909 - val_accuracy: 0.9027\n",
      "Epoch 200/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1310 - accuracy: 0.9716 - val_loss: 0.3570 - val_accuracy: 0.9107\n",
      "308/308 [==============================] - 4s 10ms/step\n",
      "132/132 [==============================] - 1s 7ms/step\n",
      "Epoch 1/200\n",
      "615/615 [==============================] - 26s 26ms/step - loss: 3.5077 - accuracy: 0.1399 - val_loss: 2.6363 - val_accuracy: 0.2895\n",
      "Epoch 2/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 2.6030 - accuracy: 0.2987 - val_loss: 2.0051 - val_accuracy: 0.4373\n",
      "Epoch 3/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 2.2195 - accuracy: 0.3829 - val_loss: 1.7818 - val_accuracy: 0.4931\n",
      "Epoch 4/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 1.9887 - accuracy: 0.4319 - val_loss: 1.4650 - val_accuracy: 0.5594\n",
      "Epoch 5/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 1.7517 - accuracy: 0.4903 - val_loss: 1.3451 - val_accuracy: 0.6106\n",
      "Epoch 6/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 1.5832 - accuracy: 0.5336 - val_loss: 1.1135 - val_accuracy: 0.6631\n",
      "Epoch 7/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 1.4625 - accuracy: 0.5696 - val_loss: 1.0566 - val_accuracy: 0.6901\n",
      "Epoch 8/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 1.3067 - accuracy: 0.6088 - val_loss: 0.9128 - val_accuracy: 0.7313\n",
      "Epoch 9/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 1.1835 - accuracy: 0.6470 - val_loss: 0.8466 - val_accuracy: 0.7450\n",
      "Epoch 10/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 1.0582 - accuracy: 0.6771 - val_loss: 0.7448 - val_accuracy: 0.7834\n",
      "Epoch 11/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.9709 - accuracy: 0.7015 - val_loss: 0.7683 - val_accuracy: 0.7791\n",
      "Epoch 12/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.8894 - accuracy: 0.7309 - val_loss: 0.6363 - val_accuracy: 0.8116\n",
      "Epoch 13/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.8149 - accuracy: 0.7543 - val_loss: 0.5906 - val_accuracy: 0.8331\n",
      "Epoch 14/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.7448 - accuracy: 0.7757 - val_loss: 0.5666 - val_accuracy: 0.8364\n",
      "Epoch 15/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6632 - accuracy: 0.7981 - val_loss: 0.5428 - val_accuracy: 0.8466\n",
      "Epoch 16/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.6206 - accuracy: 0.8159 - val_loss: 0.5295 - val_accuracy: 0.8459\n",
      "Epoch 17/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.5827 - accuracy: 0.8252 - val_loss: 0.5473 - val_accuracy: 0.8445\n",
      "Epoch 18/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.5325 - accuracy: 0.8426 - val_loss: 0.4910 - val_accuracy: 0.8629\n",
      "Epoch 19/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.4820 - accuracy: 0.8606 - val_loss: 0.4748 - val_accuracy: 0.8700\n",
      "Epoch 20/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.4548 - accuracy: 0.8667 - val_loss: 0.4498 - val_accuracy: 0.8757\n",
      "Epoch 21/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.4094 - accuracy: 0.8833 - val_loss: 0.4419 - val_accuracy: 0.8795\n",
      "Epoch 22/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.4078 - accuracy: 0.8838 - val_loss: 0.4319 - val_accuracy: 0.8835\n",
      "Epoch 23/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.3625 - accuracy: 0.8988 - val_loss: 0.4221 - val_accuracy: 0.8828\n",
      "Epoch 24/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.3456 - accuracy: 0.8997 - val_loss: 0.4069 - val_accuracy: 0.8871\n",
      "Epoch 25/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.3381 - accuracy: 0.9010 - val_loss: 0.4196 - val_accuracy: 0.8835\n",
      "Epoch 26/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.3150 - accuracy: 0.9135 - val_loss: 0.4009 - val_accuracy: 0.8894\n",
      "Epoch 27/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.3020 - accuracy: 0.9138 - val_loss: 0.3859 - val_accuracy: 0.8946\n",
      "Epoch 28/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.2868 - accuracy: 0.9192 - val_loss: 0.4078 - val_accuracy: 0.8904\n",
      "Epoch 29/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.2811 - accuracy: 0.9224 - val_loss: 0.3765 - val_accuracy: 0.9010\n",
      "Epoch 30/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2613 - accuracy: 0.9284 - val_loss: 0.3972 - val_accuracy: 0.8949\n",
      "Epoch 31/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.2440 - accuracy: 0.9353 - val_loss: 0.3742 - val_accuracy: 0.8999\n",
      "Epoch 32/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.2384 - accuracy: 0.9357 - val_loss: 0.3817 - val_accuracy: 0.9006\n",
      "Epoch 33/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.2289 - accuracy: 0.9388 - val_loss: 0.3806 - val_accuracy: 0.9067\n",
      "Epoch 34/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.2275 - accuracy: 0.9391 - val_loss: 0.3699 - val_accuracy: 0.9022\n",
      "Epoch 35/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.2117 - accuracy: 0.9433 - val_loss: 0.3661 - val_accuracy: 0.9046\n",
      "Epoch 36/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.2048 - accuracy: 0.9478 - val_loss: 0.3745 - val_accuracy: 0.9027\n",
      "Epoch 37/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.2010 - accuracy: 0.9458 - val_loss: 0.3602 - val_accuracy: 0.9072\n",
      "Epoch 38/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1879 - accuracy: 0.9517 - val_loss: 0.3639 - val_accuracy: 0.9074\n",
      "Epoch 39/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1973 - accuracy: 0.9489 - val_loss: 0.3735 - val_accuracy: 0.9039\n",
      "Epoch 40/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1888 - accuracy: 0.9510 - val_loss: 0.3680 - val_accuracy: 0.9036\n",
      "Epoch 41/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1900 - accuracy: 0.9507 - val_loss: 0.3670 - val_accuracy: 0.9051\n",
      "Epoch 42/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1720 - accuracy: 0.9568 - val_loss: 0.3471 - val_accuracy: 0.9115\n",
      "Epoch 43/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1645 - accuracy: 0.9595 - val_loss: 0.3494 - val_accuracy: 0.9126\n",
      "Epoch 44/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1679 - accuracy: 0.9580 - val_loss: 0.3739 - val_accuracy: 0.9029\n",
      "Epoch 45/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1574 - accuracy: 0.9625 - val_loss: 0.3574 - val_accuracy: 0.9098\n",
      "Epoch 46/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1640 - accuracy: 0.9605 - val_loss: 0.3454 - val_accuracy: 0.9119\n",
      "Epoch 47/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1604 - accuracy: 0.9589 - val_loss: 0.3539 - val_accuracy: 0.9117\n",
      "Epoch 48/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1591 - accuracy: 0.9603 - val_loss: 0.3580 - val_accuracy: 0.9091\n",
      "Epoch 49/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1537 - accuracy: 0.9639 - val_loss: 0.3478 - val_accuracy: 0.9115\n",
      "Epoch 50/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1538 - accuracy: 0.9636 - val_loss: 0.3355 - val_accuracy: 0.9155\n",
      "Epoch 51/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1575 - accuracy: 0.9610 - val_loss: 0.3509 - val_accuracy: 0.9110\n",
      "Epoch 52/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1458 - accuracy: 0.9654 - val_loss: 0.3513 - val_accuracy: 0.9089\n",
      "Epoch 53/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1508 - accuracy: 0.9658 - val_loss: 0.3487 - val_accuracy: 0.9112\n",
      "Epoch 54/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1478 - accuracy: 0.9665 - val_loss: 0.3466 - val_accuracy: 0.9129\n",
      "Epoch 55/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1422 - accuracy: 0.9689 - val_loss: 0.3440 - val_accuracy: 0.9148\n",
      "Epoch 56/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1404 - accuracy: 0.9679 - val_loss: 0.3380 - val_accuracy: 0.9162\n",
      "Epoch 57/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1401 - accuracy: 0.9670 - val_loss: 0.3348 - val_accuracy: 0.9164\n",
      "Epoch 58/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1337 - accuracy: 0.9713 - val_loss: 0.3425 - val_accuracy: 0.9136\n",
      "Epoch 59/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1383 - accuracy: 0.9700 - val_loss: 0.3419 - val_accuracy: 0.9148\n",
      "Epoch 60/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1299 - accuracy: 0.9713 - val_loss: 0.3417 - val_accuracy: 0.9124\n",
      "Epoch 61/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1335 - accuracy: 0.9696 - val_loss: 0.3355 - val_accuracy: 0.9136\n",
      "Epoch 62/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1327 - accuracy: 0.9690 - val_loss: 0.3626 - val_accuracy: 0.9098\n",
      "Epoch 63/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1320 - accuracy: 0.9703 - val_loss: 0.3346 - val_accuracy: 0.9174\n",
      "Epoch 64/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1261 - accuracy: 0.9723 - val_loss: 0.3295 - val_accuracy: 0.9188\n",
      "Epoch 65/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1296 - accuracy: 0.9711 - val_loss: 0.3381 - val_accuracy: 0.9157\n",
      "Epoch 66/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1349 - accuracy: 0.9689 - val_loss: 0.3345 - val_accuracy: 0.9190\n",
      "Epoch 67/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1249 - accuracy: 0.9720 - val_loss: 0.3309 - val_accuracy: 0.9179\n",
      "Epoch 68/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1315 - accuracy: 0.9689 - val_loss: 0.3349 - val_accuracy: 0.9176\n",
      "Epoch 69/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1227 - accuracy: 0.9746 - val_loss: 0.3345 - val_accuracy: 0.9164\n",
      "Epoch 70/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1244 - accuracy: 0.9732 - val_loss: 0.3369 - val_accuracy: 0.9143\n",
      "Epoch 71/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1239 - accuracy: 0.9731 - val_loss: 0.3286 - val_accuracy: 0.9157\n",
      "Epoch 72/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1261 - accuracy: 0.9714 - val_loss: 0.3333 - val_accuracy: 0.9155\n",
      "Epoch 73/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1262 - accuracy: 0.9732 - val_loss: 0.3430 - val_accuracy: 0.9138\n",
      "Epoch 74/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1243 - accuracy: 0.9740 - val_loss: 0.3312 - val_accuracy: 0.9167\n",
      "Epoch 75/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1248 - accuracy: 0.9712 - val_loss: 0.3238 - val_accuracy: 0.9195\n",
      "Epoch 76/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1214 - accuracy: 0.9738 - val_loss: 0.3415 - val_accuracy: 0.9148\n",
      "Epoch 77/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1175 - accuracy: 0.9763 - val_loss: 0.3342 - val_accuracy: 0.9164\n",
      "Epoch 78/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1252 - accuracy: 0.9738 - val_loss: 0.3316 - val_accuracy: 0.9183\n",
      "Epoch 79/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1227 - accuracy: 0.9724 - val_loss: 0.3351 - val_accuracy: 0.9174\n",
      "Epoch 80/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1145 - accuracy: 0.9744 - val_loss: 0.3366 - val_accuracy: 0.9138\n",
      "Epoch 81/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1156 - accuracy: 0.9751 - val_loss: 0.3384 - val_accuracy: 0.9167\n",
      "Epoch 82/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.1148 - accuracy: 0.9769 - val_loss: 0.3321 - val_accuracy: 0.9160\n",
      "Epoch 83/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1191 - accuracy: 0.9732 - val_loss: 0.3290 - val_accuracy: 0.9162\n",
      "Epoch 84/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1230 - accuracy: 0.9724 - val_loss: 0.3352 - val_accuracy: 0.9162\n",
      "Epoch 85/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1207 - accuracy: 0.9734 - val_loss: 0.3308 - val_accuracy: 0.9200\n",
      "Epoch 86/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1223 - accuracy: 0.9733 - val_loss: 0.3465 - val_accuracy: 0.9164\n",
      "Epoch 87/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1245 - accuracy: 0.9718 - val_loss: 0.3518 - val_accuracy: 0.9112\n",
      "Epoch 88/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1230 - accuracy: 0.9727 - val_loss: 0.3297 - val_accuracy: 0.9176\n",
      "Epoch 89/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1203 - accuracy: 0.9752 - val_loss: 0.3294 - val_accuracy: 0.9174\n",
      "Epoch 90/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1203 - accuracy: 0.9735 - val_loss: 0.3257 - val_accuracy: 0.9190\n",
      "Epoch 91/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1190 - accuracy: 0.9747 - val_loss: 0.3494 - val_accuracy: 0.9115\n",
      "Epoch 92/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1243 - accuracy: 0.9737 - val_loss: 0.3349 - val_accuracy: 0.9131\n",
      "Epoch 93/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1177 - accuracy: 0.9756 - val_loss: 0.3381 - val_accuracy: 0.9155\n",
      "Epoch 94/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1136 - accuracy: 0.9771 - val_loss: 0.3432 - val_accuracy: 0.9145\n",
      "Epoch 95/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1185 - accuracy: 0.9749 - val_loss: 0.3299 - val_accuracy: 0.9181\n",
      "Epoch 96/200\n",
      "615/615 [==============================] - 18s 29ms/step - loss: 0.1200 - accuracy: 0.9749 - val_loss: 0.3328 - val_accuracy: 0.9157\n",
      "Epoch 97/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1183 - accuracy: 0.9735 - val_loss: 0.3247 - val_accuracy: 0.9183\n",
      "Epoch 98/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1259 - accuracy: 0.9722 - val_loss: 0.3303 - val_accuracy: 0.9176\n",
      "Epoch 99/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1217 - accuracy: 0.9741 - val_loss: 0.3319 - val_accuracy: 0.9174\n",
      "Epoch 100/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1237 - accuracy: 0.9733 - val_loss: 0.3194 - val_accuracy: 0.9188\n",
      "Epoch 101/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1218 - accuracy: 0.9723 - val_loss: 0.3430 - val_accuracy: 0.9157\n",
      "Epoch 102/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1123 - accuracy: 0.9760 - val_loss: 0.3399 - val_accuracy: 0.9162\n",
      "Epoch 103/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1214 - accuracy: 0.9737 - val_loss: 0.3380 - val_accuracy: 0.9145\n",
      "Epoch 104/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1206 - accuracy: 0.9734 - val_loss: 0.3377 - val_accuracy: 0.9160\n",
      "Epoch 105/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.1214 - accuracy: 0.9713 - val_loss: 0.3413 - val_accuracy: 0.9162\n",
      "Epoch 106/200\n",
      "615/615 [==============================] - 14s 24ms/step - loss: 0.1220 - accuracy: 0.9729 - val_loss: 0.3269 - val_accuracy: 0.9176\n",
      "Epoch 107/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1187 - accuracy: 0.9746 - val_loss: 0.3302 - val_accuracy: 0.9188\n",
      "Epoch 108/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1177 - accuracy: 0.9744 - val_loss: 0.3317 - val_accuracy: 0.9150\n",
      "Epoch 109/200\n",
      "615/615 [==============================] - 18s 29ms/step - loss: 0.1146 - accuracy: 0.9769 - val_loss: 0.3283 - val_accuracy: 0.9183\n",
      "Epoch 110/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1233 - accuracy: 0.9726 - val_loss: 0.3420 - val_accuracy: 0.9152\n",
      "Epoch 111/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1234 - accuracy: 0.9738 - val_loss: 0.3395 - val_accuracy: 0.9160\n",
      "Epoch 112/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1204 - accuracy: 0.9733 - val_loss: 0.3307 - val_accuracy: 0.9179\n",
      "Epoch 113/200\n",
      "615/615 [==============================] - 18s 29ms/step - loss: 0.1206 - accuracy: 0.9747 - val_loss: 0.3340 - val_accuracy: 0.9148\n",
      "Epoch 114/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1174 - accuracy: 0.9734 - val_loss: 0.3257 - val_accuracy: 0.9167\n",
      "Epoch 115/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1142 - accuracy: 0.9761 - val_loss: 0.3272 - val_accuracy: 0.9176\n",
      "Epoch 116/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1149 - accuracy: 0.9778 - val_loss: 0.3263 - val_accuracy: 0.9169\n",
      "Epoch 117/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1137 - accuracy: 0.9782 - val_loss: 0.3266 - val_accuracy: 0.9202\n",
      "Epoch 118/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.1188 - accuracy: 0.9736 - val_loss: 0.3265 - val_accuracy: 0.9181\n",
      "Epoch 119/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1131 - accuracy: 0.9763 - val_loss: 0.3261 - val_accuracy: 0.9179\n",
      "Epoch 120/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1179 - accuracy: 0.9756 - val_loss: 0.3225 - val_accuracy: 0.9183\n",
      "Epoch 121/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1185 - accuracy: 0.9756 - val_loss: 0.3365 - val_accuracy: 0.9157\n",
      "Epoch 122/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1190 - accuracy: 0.9731 - val_loss: 0.3423 - val_accuracy: 0.9157\n",
      "Epoch 123/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1188 - accuracy: 0.9741 - val_loss: 0.3436 - val_accuracy: 0.9150\n",
      "Epoch 124/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1208 - accuracy: 0.9726 - val_loss: 0.3325 - val_accuracy: 0.9169\n",
      "Epoch 125/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1196 - accuracy: 0.9757 - val_loss: 0.3340 - val_accuracy: 0.9181\n",
      "Epoch 126/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1245 - accuracy: 0.9724 - val_loss: 0.3339 - val_accuracy: 0.9176\n",
      "Epoch 127/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1184 - accuracy: 0.9737 - val_loss: 0.3335 - val_accuracy: 0.9171\n",
      "Epoch 128/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1202 - accuracy: 0.9723 - val_loss: 0.3202 - val_accuracy: 0.9188\n",
      "Epoch 129/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1175 - accuracy: 0.9757 - val_loss: 0.3253 - val_accuracy: 0.9174\n",
      "Epoch 130/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1225 - accuracy: 0.9731 - val_loss: 0.3277 - val_accuracy: 0.9167\n",
      "Epoch 131/200\n",
      "615/615 [==============================] - 19s 31ms/step - loss: 0.1250 - accuracy: 0.9721 - val_loss: 0.3281 - val_accuracy: 0.9188\n",
      "Epoch 132/200\n",
      "615/615 [==============================] - 17s 28ms/step - loss: 0.1153 - accuracy: 0.9763 - val_loss: 0.3331 - val_accuracy: 0.9181\n",
      "Epoch 133/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1197 - accuracy: 0.9745 - val_loss: 0.3308 - val_accuracy: 0.9183\n",
      "Epoch 134/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1216 - accuracy: 0.9754 - val_loss: 0.3313 - val_accuracy: 0.9160\n",
      "Epoch 135/200\n",
      "615/615 [==============================] - 17s 28ms/step - loss: 0.1107 - accuracy: 0.9777 - val_loss: 0.3359 - val_accuracy: 0.9167\n",
      "Epoch 136/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1176 - accuracy: 0.9743 - val_loss: 0.3278 - val_accuracy: 0.9212\n",
      "Epoch 137/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1250 - accuracy: 0.9711 - val_loss: 0.3298 - val_accuracy: 0.9190\n",
      "Epoch 138/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1227 - accuracy: 0.9727 - val_loss: 0.3395 - val_accuracy: 0.9162\n",
      "Epoch 139/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1157 - accuracy: 0.9743 - val_loss: 0.3286 - val_accuracy: 0.9186\n",
      "Epoch 140/200\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.1118 - accuracy: 0.9759 - val_loss: 0.3370 - val_accuracy: 0.9167\n",
      "Epoch 141/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1157 - accuracy: 0.9736 - val_loss: 0.3301 - val_accuracy: 0.9167\n",
      "Epoch 142/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1199 - accuracy: 0.9749 - val_loss: 0.3277 - val_accuracy: 0.9188\n",
      "Epoch 143/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1220 - accuracy: 0.9729 - val_loss: 0.3243 - val_accuracy: 0.9195\n",
      "Epoch 144/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1184 - accuracy: 0.9743 - val_loss: 0.3316 - val_accuracy: 0.9164\n",
      "Epoch 145/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.1202 - accuracy: 0.9737 - val_loss: 0.3341 - val_accuracy: 0.9171\n",
      "Epoch 146/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1208 - accuracy: 0.9729 - val_loss: 0.3285 - val_accuracy: 0.9157\n",
      "Epoch 147/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1181 - accuracy: 0.9761 - val_loss: 0.3367 - val_accuracy: 0.9167\n",
      "Epoch 148/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1183 - accuracy: 0.9738 - val_loss: 0.3389 - val_accuracy: 0.9169\n",
      "Epoch 149/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1160 - accuracy: 0.9742 - val_loss: 0.3422 - val_accuracy: 0.9148\n",
      "Epoch 150/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1144 - accuracy: 0.9751 - val_loss: 0.3356 - val_accuracy: 0.9167\n",
      "Epoch 151/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1195 - accuracy: 0.9727 - val_loss: 0.3400 - val_accuracy: 0.9145\n",
      "Epoch 152/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1135 - accuracy: 0.9777 - val_loss: 0.3336 - val_accuracy: 0.9152\n",
      "Epoch 153/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1225 - accuracy: 0.9729 - val_loss: 0.3499 - val_accuracy: 0.9122\n",
      "Epoch 154/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1118 - accuracy: 0.9762 - val_loss: 0.3267 - val_accuracy: 0.9200\n",
      "Epoch 155/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1266 - accuracy: 0.9708 - val_loss: 0.3286 - val_accuracy: 0.9183\n",
      "Epoch 156/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1119 - accuracy: 0.9756 - val_loss: 0.3276 - val_accuracy: 0.9167\n",
      "Epoch 157/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1107 - accuracy: 0.9780 - val_loss: 0.3301 - val_accuracy: 0.9188\n",
      "Epoch 158/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1135 - accuracy: 0.9754 - val_loss: 0.3374 - val_accuracy: 0.9167\n",
      "Epoch 159/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1128 - accuracy: 0.9748 - val_loss: 0.3228 - val_accuracy: 0.9195\n",
      "Epoch 160/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1168 - accuracy: 0.9747 - val_loss: 0.3344 - val_accuracy: 0.9169\n",
      "Epoch 161/200\n",
      "615/615 [==============================] - 14s 24ms/step - loss: 0.1171 - accuracy: 0.9743 - val_loss: 0.3355 - val_accuracy: 0.9195\n",
      "Epoch 162/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1134 - accuracy: 0.9752 - val_loss: 0.3537 - val_accuracy: 0.9115\n",
      "Epoch 163/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1197 - accuracy: 0.9745 - val_loss: 0.3299 - val_accuracy: 0.9188\n",
      "Epoch 164/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1209 - accuracy: 0.9750 - val_loss: 0.3382 - val_accuracy: 0.9162\n",
      "Epoch 165/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1233 - accuracy: 0.9743 - val_loss: 0.3243 - val_accuracy: 0.9200\n",
      "Epoch 166/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1130 - accuracy: 0.9774 - val_loss: 0.3483 - val_accuracy: 0.9112\n",
      "Epoch 167/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1204 - accuracy: 0.9726 - val_loss: 0.3289 - val_accuracy: 0.9171\n",
      "Epoch 168/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1208 - accuracy: 0.9746 - val_loss: 0.3248 - val_accuracy: 0.9193\n",
      "Epoch 169/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.1221 - accuracy: 0.9734 - val_loss: 0.3413 - val_accuracy: 0.9155\n",
      "Epoch 170/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1186 - accuracy: 0.9748 - val_loss: 0.3363 - val_accuracy: 0.9155\n",
      "Epoch 171/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1223 - accuracy: 0.9726 - val_loss: 0.3306 - val_accuracy: 0.9162\n",
      "Epoch 172/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1203 - accuracy: 0.9745 - val_loss: 0.3363 - val_accuracy: 0.9162\n",
      "Epoch 173/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1210 - accuracy: 0.9733 - val_loss: 0.3338 - val_accuracy: 0.9186\n",
      "Epoch 174/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1166 - accuracy: 0.9750 - val_loss: 0.3461 - val_accuracy: 0.9129\n",
      "Epoch 175/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1188 - accuracy: 0.9749 - val_loss: 0.3335 - val_accuracy: 0.9179\n",
      "Epoch 176/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1199 - accuracy: 0.9745 - val_loss: 0.3248 - val_accuracy: 0.9202\n",
      "Epoch 177/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1234 - accuracy: 0.9711 - val_loss: 0.3198 - val_accuracy: 0.9200\n",
      "Epoch 178/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1141 - accuracy: 0.9759 - val_loss: 0.3334 - val_accuracy: 0.9171\n",
      "Epoch 179/200\n",
      "615/615 [==============================] - 17s 27ms/step - loss: 0.1190 - accuracy: 0.9756 - val_loss: 0.3203 - val_accuracy: 0.9188\n",
      "Epoch 180/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1236 - accuracy: 0.9737 - val_loss: 0.3256 - val_accuracy: 0.9176\n",
      "Epoch 181/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1185 - accuracy: 0.9760 - val_loss: 0.3348 - val_accuracy: 0.9169\n",
      "Epoch 182/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1217 - accuracy: 0.9724 - val_loss: 0.3734 - val_accuracy: 0.9053\n",
      "Epoch 183/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1136 - accuracy: 0.9750 - val_loss: 0.3347 - val_accuracy: 0.9148\n",
      "Epoch 184/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1187 - accuracy: 0.9751 - val_loss: 0.3374 - val_accuracy: 0.9141\n",
      "Epoch 185/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1184 - accuracy: 0.9754 - val_loss: 0.3300 - val_accuracy: 0.9197\n",
      "Epoch 186/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1235 - accuracy: 0.9733 - val_loss: 0.3275 - val_accuracy: 0.9181\n",
      "Epoch 187/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1217 - accuracy: 0.9723 - val_loss: 0.3380 - val_accuracy: 0.9171\n",
      "Epoch 188/200\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.1192 - accuracy: 0.9749 - val_loss: 0.3383 - val_accuracy: 0.9155\n",
      "Epoch 189/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1158 - accuracy: 0.9761 - val_loss: 0.3263 - val_accuracy: 0.9193\n",
      "Epoch 190/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1260 - accuracy: 0.9713 - val_loss: 0.3246 - val_accuracy: 0.9181\n",
      "Epoch 191/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1162 - accuracy: 0.9736 - val_loss: 0.3366 - val_accuracy: 0.9179\n",
      "Epoch 192/200\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.1153 - accuracy: 0.9760 - val_loss: 0.3301 - val_accuracy: 0.9167\n",
      "Epoch 193/200\n",
      "615/615 [==============================] - 16s 27ms/step - loss: 0.1184 - accuracy: 0.9735 - val_loss: 0.3257 - val_accuracy: 0.9190\n",
      "Epoch 194/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1174 - accuracy: 0.9762 - val_loss: 0.3453 - val_accuracy: 0.9138\n",
      "Epoch 195/200\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.1141 - accuracy: 0.9756 - val_loss: 0.3324 - val_accuracy: 0.9183\n",
      "Epoch 196/200\n",
      "615/615 [==============================] - 14s 22ms/step - loss: 0.1258 - accuracy: 0.9727 - val_loss: 0.3301 - val_accuracy: 0.9193\n",
      "Epoch 197/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1167 - accuracy: 0.9741 - val_loss: 0.3290 - val_accuracy: 0.9179\n",
      "Epoch 198/200\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.1233 - accuracy: 0.9725 - val_loss: 0.3269 - val_accuracy: 0.9181\n",
      "Epoch 199/200\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.1137 - accuracy: 0.9756 - val_loss: 0.3386 - val_accuracy: 0.9157\n",
      "Epoch 200/200\n",
      "615/615 [==============================] - 13s 21ms/step - loss: 0.1166 - accuracy: 0.9739 - val_loss: 0.3253 - val_accuracy: 0.9190\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dropout, Input, Conv1D, MaxPooling1D,\n",
    "    Flatten, Dense, Activation, TimeDistributed, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "def cnn(x):\n",
    "    #print(x.shape)\n",
    "    #x = Reshape((25, 20,10))(x)  \n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=9, padding='same', kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(MaxPooling1D(pool_size=8, strides=2))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=3, padding=\"same\", kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(Dropout(0.5))(x)\n",
    "    x = TimeDistributed(Activation('relu'))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "def Bi_LSTMModel(input_shape,x):\n",
    "    #model = Sequential()\n",
    "    # Hidden dimensions\n",
    "    hidden_dim = 200\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    x = Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=input_shape)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    x = Bidirectional(LSTM(hidden_dim, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    #x = Dropout(0.2093)(x)\n",
    "    x = Flatten()(x)\n",
    "    # ( ,10000)\n",
    "    return x\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dropout, Input, Conv1D, MaxPooling1D,\n",
    "    Flatten, Dense, Activation, TimeDistributed, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Define the teacher model\n",
    "def create_teacher_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = cnn(x)  # Use the cnn function from your code\n",
    "    x = Bi_LSTMModel(x.shape[1:], x)  # Use the Bi_LSTMModel function from your code\n",
    "    x = Dense(512, activation='tanh')(x)\n",
    "    x = BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    teacher_model = Model(inputs=inputs, outputs=output_layer)\n",
    "    return teacher_model\n",
    "\n",
    "# Define the student model (smaller model)\n",
    "def create_student_model(input_shape, num_classes):\n",
    "    # Define an additional input for teacher model's predictions\n",
    "    teacher_predictions = Input(shape=(num_classes,))\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = cnn(x)  # Use the cnn function from your code\n",
    "    x = Bi_LSTMModel(x.shape[1:], x)  # Use the Bi_LSTMModel function from your code\n",
    "    x = Dense(256, activation='tanh')(x)  # Smaller hidden layer\n",
    "    x = BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)(x)\n",
    "    \n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    student_model = Model(inputs=[inputs, teacher_predictions], outputs=output_layer)\n",
    "    return student_model\n",
    "\n",
    "# Create teacher and student models\n",
    "num_classes = 52\n",
    "teacher_model = create_teacher_model((25, 20, 10), num_classes)\n",
    "student_model = create_student_model((25, 20, 10), num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# Define the learning rate schedule\n",
    "initial_learning_rate = 1e-3\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "# Compile the teacher model\n",
    "teacher_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule,\n",
    "                                                         beta_1=0.9,\n",
    "                                                         beta_2=0.999,\n",
    "                                                         amsgrad=False),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the teacher model\n",
    "teacher_model.fit(x_train, y_train, epochs=200, batch_size=16, validation_data=(x_test, y_test))\n",
    "\n",
    "# Compile the student model with the learning rate schedule and knowledge distillation loss\n",
    "student_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule,\n",
    "                                                         beta_1=0.9,\n",
    "                                                         beta_2=0.999,\n",
    "                                                         amsgrad=False),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the student model using knowledge distillation\n",
    "history = student_model.fit([x_train, teacher_model.predict(x_train)],\n",
    "                            y_train,\n",
    "                            epochs=200,\n",
    "                            batch_size=16,\n",
    "                            validation_data=([x_test, teacher_model.predict(x_test)], y_test),\n",
    "                            verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6062.625658,
   "end_time": "2023-10-11T19:35:43.166525",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-11T17:54:40.540867",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
