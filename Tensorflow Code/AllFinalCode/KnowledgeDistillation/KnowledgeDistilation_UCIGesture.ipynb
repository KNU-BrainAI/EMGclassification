{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1afe28",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:35.952460Z",
     "iopub.status.busy": "2023-10-11T12:58:35.951799Z",
     "iopub.status.idle": "2023-10-11T12:58:36.205079Z",
     "shell.execute_reply": "2023-10-11T12:58:36.204005Z"
    },
    "papermill": {
     "duration": 0.262055,
     "end_time": "2023-10-11T12:58:36.207031",
     "exception": false,
     "start_time": "2023-10-11T12:58:35.944976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasetfornina/ninaprodb1train.pkl\n",
      "/kaggle/input/datasetfornina/ninaprodb1test.pkl\n",
      "/kaggle/input/newninaprodb4/ninaprodb44test.pkl\n",
      "/kaggle/input/newninaprodb4/ninaprodb44train.pkl\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/3.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/5.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/4.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/7.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/0.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Edited_label/6.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/3.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/5.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/4.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/7.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/0.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_label/6.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/33_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/21_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/24_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/23_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/11_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/25_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/11_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/20_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/23_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/27_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/32_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/30_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/16_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/8_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/1_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/1_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/18_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/6_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/9_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/19_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/31_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/26_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/8_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/20_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/4_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/21_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/9_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/5_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/3_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/25_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/10_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/30_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/15_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/22_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/19_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/35_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/31_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/32_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/5_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/34_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/36_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/27_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/2_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/35_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/12_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/13_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/15_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/14_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/33_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/14_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/6_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/16_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/3_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/12_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/7_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/28_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/22_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/4_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/7_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/29_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/26_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/34_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/18_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/29_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/28_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/10_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/13_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/17_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/2_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/17_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/24_1.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw_csv/36_2.csv\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/README.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/17/2_raw_data_11-20_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/17/1_raw_data_11-19_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/19/2_raw_data_12-11_26.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/19/1_raw_data_12-10_26.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/22/2_raw_data_12-39_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/22/1_raw_data_12-37_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/35/1_raw_data_10-03_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/35/2_raw_data_10-05_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/23/1_raw_data_13-18_05.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/23/2_raw_data_13-19_05.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/07/1_raw_data_18-48_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/07/2_raw_data_18-50_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/10/2_raw_data_11-10_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/10/1_raw_data_11-08_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/36/1_raw_data_13-03_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/36/2_raw_data_13-04_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/05/1_raw_data_10-28_30.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/05/2_raw_data_10-29_30.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/20/2_raw_data_11-43_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/20/1_raw_data_11-41_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/06/1_raw_data_10-38_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/06/2_raw_data_10-40_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/27/2_raw_data_12-20_06.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/27/1_raw_data_12-19_06.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/02/1_raw_data_14-19_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/02/2_raw_data_14-21_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/32/2_raw_data_12-06_27.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/32/1_raw_data_12-04_27.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/25/1_raw_data_14-51_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/25/2_raw_data_14-53_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/12/1_raw_data_11-35_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/12/2_raw_data_11-36_28.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/04/2_raw_data_18-03_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/04/1_raw_data_18-02_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/31/2_raw_data_11-16_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/31/1_raw_data_11-15_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/34/2_raw_data_10-53_07.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/34/1_raw_data_10-51_07.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/18/1_raw_data_12-35_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/18/2_raw_data_12-37_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/28/2_raw_data_12-11_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/28/1_raw_data_12-10_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/16/1_raw_data_12-12_25.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/16/2_raw_data_12-14_25.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/13/2_raw_data_13-29_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/13/1_raw_data_13-26_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/26/2_raw_data_10-23_29.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/26/1_raw_data_10-22_29.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/08/2_raw_data_12-16_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/08/1_raw_data_12-14_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/15/2_raw_data_08-51_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/15/1_raw_data_08-49_13.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/09/2_raw_data_12-43_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/09/1_raw_data_12-41_23.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/30/1_raw_data_09-49_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/30/2_raw_data_09-50_21.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/14/2_raw_data_09-51_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/14/1_raw_data_09-50_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/03/2_raw_data_09-34_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/03/1_raw_data_09-32_11.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/21/1_raw_data_20-28_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/21/2_raw_data_20-30_24.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/11/2_raw_data_13-13_18.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/11/1_raw_data_13-11_18.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/01/2_raw_data_13-13_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/01/1_raw_data_13-12_22.03.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/33/2_raw_data_09-50_12.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/33/1_raw_data_09-49_12.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/29/2_raw_data_10-18_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/29/1_raw_data_10-17_15.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/24/2_raw_data_10-17_12.04.16.txt\n",
      "/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw/24/1_raw_data_10-16_12.04.16.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38cacd2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:36.220077Z",
     "iopub.status.busy": "2023-10-11T12:58:36.219112Z",
     "iopub.status.idle": "2023-10-11T12:58:51.579058Z",
     "shell.execute_reply": "2023-10-11T12:58:51.577984Z"
    },
    "papermill": {
     "duration": 15.368969,
     "end_time": "2023-10-11T12:58:51.581501",
     "exception": false,
     "start_time": "2023-10-11T12:58:36.212532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "# ... (other code) ...\n",
    "\n",
    "\n",
    "import random\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5f3c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:51.595031Z",
     "iopub.status.busy": "2023-10-11T12:58:51.594370Z",
     "iopub.status.idle": "2023-10-11T12:58:53.131623Z",
     "shell.execute_reply": "2023-10-11T12:58:53.130550Z"
    },
    "papermill": {
     "duration": 1.54666,
     "end_time": "2023-10-11T12:58:53.134118",
     "exception": false,
     "start_time": "2023-10-11T12:58:51.587458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba7a74",
   "metadata": {
    "papermill": {
     "duration": 0.005814,
     "end_time": "2023-10-11T12:58:53.146388",
     "exception": false,
     "start_time": "2023-10-11T12:58:53.140574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92295cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:53.160697Z",
     "iopub.status.busy": "2023-10-11T12:58:53.159591Z",
     "iopub.status.idle": "2023-10-11T12:58:53.164862Z",
     "shell.execute_reply": "2023-10-11T12:58:53.163837Z"
    },
    "papermill": {
     "duration": 0.014561,
     "end_time": "2023-10-11T12:58:53.166829",
     "exception": false,
     "start_time": "2023-10-11T12:58:53.152268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, optimizers, Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefab972",
   "metadata": {
    "papermill": {
     "duration": 0.006167,
     "end_time": "2023-10-11T12:58:53.178915",
     "exception": false,
     "start_time": "2023-10-11T12:58:53.172748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**WORKED CODE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e2ac14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:53.191823Z",
     "iopub.status.busy": "2023-10-11T12:58:53.191488Z",
     "iopub.status.idle": "2023-10-11T12:58:53.198275Z",
     "shell.execute_reply": "2023-10-11T12:58:53.197365Z"
    },
    "papermill": {
     "duration": 0.015562,
     "end_time": "2023-10-11T12:58:53.200228",
     "exception": false,
     "start_time": "2023-10-11T12:58:53.184666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffad7b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:53.213371Z",
     "iopub.status.busy": "2023-10-11T12:58:53.212857Z",
     "iopub.status.idle": "2023-10-11T12:58:53.217473Z",
     "shell.execute_reply": "2023-10-11T12:58:53.216483Z"
    },
    "papermill": {
     "duration": 0.013375,
     "end_time": "2023-10-11T12:58:53.219431",
     "exception": false,
     "start_time": "2023-10-11T12:58:53.206056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "method = \"default\"\n",
    "dataset_type = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22f9484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T12:58:53.232880Z",
     "iopub.status.busy": "2023-10-11T12:58:53.232078Z",
     "iopub.status.idle": "2023-10-11T12:58:53.240000Z",
     "shell.execute_reply": "2023-10-11T12:58:53.239056Z"
    },
    "papermill": {
     "duration": 0.01671,
     "end_time": "2023-10-11T12:58:53.241904",
     "exception": false,
     "start_time": "2023-10-11T12:58:53.225194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dropout, Input, Conv1D, MaxPooling1D,\n",
    "    Flatten, Dense, ReLU, TimeDistributed, Reshape, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "from tensorflow.keras import regularizers, initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3a5b7",
   "metadata": {
    "papermill": {
     "duration": 4.401368,
     "end_time": "2023-10-11T14:37:05.131696",
     "exception": false,
     "start_time": "2023-10-11T14:37:00.730328",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5821c3e2",
   "metadata": {
    "papermill": {
     "duration": 4.184516,
     "end_time": "2023-10-11T14:37:22.207387",
     "exception": false,
     "start_time": "2023-10-11T14:37:18.022871",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f38caf4",
   "metadata": {
    "papermill": {
     "duration": 4.31052,
     "end_time": "2023-10-11T14:37:40.089301",
     "exception": false,
     "start_time": "2023-10-11T14:37:35.778781",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdca74d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T14:37:48.802646Z",
     "iopub.status.busy": "2023-10-11T14:37:48.802307Z",
     "iopub.status.idle": "2023-10-11T14:37:48.807235Z",
     "shell.execute_reply": "2023-10-11T14:37:48.806115Z"
    },
    "papermill": {
     "duration": 4.479062,
     "end_time": "2023-10-11T14:37:48.809183",
     "exception": false,
     "start_time": "2023-10-11T14:37:44.330121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "835ee8f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T14:38:15.441487Z",
     "iopub.status.busy": "2023-10-11T14:38:15.441143Z",
     "iopub.status.idle": "2023-10-11T14:38:24.586977Z",
     "shell.execute_reply": "2023-10-11T14:38:24.585982Z"
    },
    "papermill": {
     "duration": 13.419188,
     "end_time": "2023-10-11T14:38:24.589080",
     "exception": false,
     "start_time": "2023-10-11T14:38:11.169892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from scipy import stats\n",
    "from keras import Sequential,layers,Input,Model,optimizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Conv1D, TimeDistributed, LSTM, Dense, Flatten, LeakyReLU, MaxPooling1D, Bidirectional, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "import tensorflow as tf\n",
    "\n",
    "def step_decay(epoch):\n",
    "  initial_lrate = 1e-4\n",
    "  drop = 0.1\n",
    "  epochs_drop = 70.0\n",
    "  lrate = initial_lrate * tf.math.pow(drop,  \n",
    "          tf.math.floor((1+epoch)/epochs_drop))\n",
    "  return lrate\n",
    "\n",
    "def create_segments_and_labels(df, time_steps,step,n_features):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "      for j in range(0, n_features):\n",
    "        segments.append(df[:,j][i: i + time_steps])\n",
    "      label = stats.mode(df[:,-1][i: i + time_steps])[0]\n",
    "      labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels\n",
    "\n",
    "time_step = 1500\n",
    "step = 1500\n",
    "num_features = 8\n",
    "\n",
    "def list_subfolders(folder_path):\n",
    "    subfolders = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # 'dirs' is a list of subdirectories in the current 'root' folder\n",
    "        subfolders.extend(dirs)\n",
    "        \n",
    "        # If you only want to look in the immediate directory (not sub-subfolders), you can break here.\n",
    "        # break\n",
    "\n",
    "    return subfolders\n",
    "\n",
    "values_to_remove = [0, 7]\n",
    "\n",
    "def remove_rows_with_values(array, column_index, values_to_remove):\n",
    "    mask = ~np.isin(array[:, column_index], values_to_remove)\n",
    "    filtered_array = array[mask]\n",
    "    return filtered_array\n",
    "\n",
    "def remove_consecutive_duplicate_rows(dataframe):\n",
    "    consecutive_duplicate_mask = dataframe.duplicated().shift(fill_value=False)\n",
    "    return dataframe.loc[~consecutive_duplicate_mask]\n",
    "\n",
    "def split_to_train_and_test(df1_filtered,df2_filtered):\n",
    "    for i in range(0,df1_filtered.shape[0]-1):\n",
    "        a = df1_filtered[i,-1]\n",
    "        b = df1_filtered[i+1,-1] \n",
    "\n",
    "        if a == 6 and b ==1:\n",
    "            border1 = i+1\n",
    "\n",
    "    rep1 = df1_filtered[:border1,:]\n",
    "    rep2 = df1_filtered[border1:,:]\n",
    "    \n",
    "    for i in range(0,df2_filtered.shape[0]-1):\n",
    "        c = df2_filtered[i,-1]\n",
    "        d = df2_filtered[i+1,-1]\n",
    "        \n",
    "        if c == 6 and d ==1:\n",
    "            border2 = i+1\n",
    "    \n",
    "    rep3 = df2_filtered[:border2,:]\n",
    "    rep4 = df2_filtered[border2:,:]\n",
    "\n",
    "    return np.vstack((rep1,rep3,rep4)),rep2\n",
    "\n",
    "data = []\n",
    "train = []\n",
    "test = []\n",
    "train_final=  np.empty((0,10))\n",
    "test_final=  np.empty((0,10))\n",
    "train_filtered=  np.empty((0,10))\n",
    "test_filtered=  np.empty((0,10))\n",
    "\n",
    "dir = r'/kaggle/input/emg-data-for-gestures-data-set/EMG/Raw'\n",
    "subfolders = list_subfolders(dir)\n",
    "\n",
    "# print(subfolders)\n",
    "\n",
    "for i in subfolders:\n",
    "    dir_list = os.listdir(dir+'/'+i)\n",
    "    df1 = pd.read_csv(dir+'/'+i+'/'+dir_list[0], delimiter='\\t').values\n",
    "    df2 = pd.read_csv(dir+'/'+i+'/'+dir_list[1], delimiter=\"\\t\").values\n",
    "\n",
    "    df1_filtered = remove_rows_with_values(df1,-1,values_to_remove)\n",
    "    df2_filtered = remove_rows_with_values(df2,-1,values_to_remove)\n",
    "\n",
    "    train, test = split_to_train_and_test(df1_filtered,df2_filtered)\n",
    "    train_final = np.vstack((train_final,train))\n",
    "    test_final = np.vstack((test_final,test))\n",
    "\n",
    "tain_final = train_final[~np.any(np.isnan(train_final), axis=1)]\n",
    "test_final = test_final[~np.any(np.isnan(test_final), axis=1)]\n",
    "\n",
    "# for value, count in zip(unique_train, count_train):\n",
    "#     print(f\"Value {value} appears {count} times in train.\")\n",
    "\n",
    "# for value, count in zip(unique_test, count_test):\n",
    "#     print(f\"Value {value} appears {count} times in test.\")\n",
    "\n",
    "\n",
    "#selecting the required number of rows\n",
    "for i in range(1,7):\n",
    "    train_selection = train_final[train_final[:,-1] == i]\n",
    "    test_selection = test_final[test_final[:,-1] == i]\n",
    "\n",
    "    train_filtered = np.vstack((train_filtered,train_selection[:162000,:]))\n",
    "    test_filtered = np.vstack((test_filtered,test_selection[:54000,:]))\n",
    "\n",
    "# print(train_filtered.shape)\n",
    "# print(test_filtered.shape)\n",
    "\n",
    "#Dropping the time column\n",
    "train_filtered = train_filtered[:,1:]\n",
    "test_filtered = test_filtered[:,1:]\n",
    "\n",
    "coeffs = pywt.wavedec(test_filtered, 'sym8')  # Using 3 decomposition levels as an example\n",
    "coeffs[1:] = (pywt.threshold(c, value=0.5, mode='soft') for c in coeffs[1:])\n",
    "test_filtered = pywt.waverec(coeffs, 'sym8')\n",
    "\n",
    "coeffs = pywt.wavedec(train_filtered, 'sym8')  # Using 3 decomposition levels as an example\n",
    "coeffs[1:] = (pywt.threshold(c, value=0.5, mode='soft') for c in coeffs[1:])\n",
    "train_filtered = pywt.waverec(coeffs, 'sym8')\n",
    "\n",
    "#Scaling the data\n",
    "sc = StandardScaler()\n",
    "train_filtered[:,:-1] = sc.fit_transform(train_filtered[:,:-1])\n",
    "test_filtered[:,:-1] = sc.transform(test_filtered[:,:-1])\n",
    "\n",
    "x_train, y_train = create_segments_and_labels(train_filtered,time_step,step,num_features)\n",
    "x_test, y_test = create_segments_and_labels(test_filtered,time_step,step,num_features)\n",
    "\n",
    "y_train_encoded = y_train - 1\n",
    "y_test_encoded = y_test - 1\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "y_train_onehot = to_categorical(y_train_encoded,num_classes)\n",
    "y_test_onehot = to_categorical(y_test_encoded,num_classes)\n",
    "\n",
    "# print(y_train_onehot.shape)\n",
    "# print(y_test_onehot.shape)\n",
    "\n",
    "n_steps,n_length,n_depth = 30,50,8\n",
    "\n",
    "x_train = x_train.reshape(-1,n_steps,n_length,n_depth)\n",
    "x_test = x_test.reshape(-1,n_steps,n_length,n_depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce9a9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T14:47:50.500335Z",
     "iopub.status.busy": "2023-10-11T14:47:50.499996Z",
     "iopub.status.idle": "2023-10-11T14:56:57.890040Z",
     "shell.execute_reply": "2023-10-11T14:56:57.889007Z"
    },
    "papermill": {
     "duration": 552.28179,
     "end_time": "2023-10-11T14:56:57.892317",
     "exception": false,
     "start_time": "2023-10-11T14:47:45.610527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 30, 128)\n",
      "11\n",
      "(None, 30, 400)\n",
      "11\n",
      "(None, 30, 400)\n",
      "11\n",
      "(None, 30, 128)\n",
      "11\n",
      "(None, 30, 400)\n",
      "11\n",
      "(None, 30, 400)\n",
      "11\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 15s 68ms/step - loss: 1.2201 - accuracy: 0.6244 - val_loss: 0.7599 - val_accuracy: 0.7349\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.8819 - accuracy: 0.7233 - val_loss: 0.8894 - val_accuracy: 0.7209\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.8113 - accuracy: 0.7836 - val_loss: 0.5593 - val_accuracy: 0.8186\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.7367 - accuracy: 0.7759 - val_loss: 0.5121 - val_accuracy: 0.8512\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.7164 - accuracy: 0.7759 - val_loss: 0.5165 - val_accuracy: 0.8465\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.6339 - accuracy: 0.7929 - val_loss: 0.4361 - val_accuracy: 0.8372\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.6271 - accuracy: 0.8053 - val_loss: 0.5488 - val_accuracy: 0.8233\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.5641 - accuracy: 0.8145 - val_loss: 0.5102 - val_accuracy: 0.8372\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.6060 - accuracy: 0.8145 - val_loss: 0.4278 - val_accuracy: 0.8558\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.5335 - accuracy: 0.8315 - val_loss: 0.4280 - val_accuracy: 0.8558\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.5496 - accuracy: 0.8253 - val_loss: 0.4642 - val_accuracy: 0.8651\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.5383 - accuracy: 0.8176 - val_loss: 0.4914 - val_accuracy: 0.8465\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.5134 - accuracy: 0.8207 - val_loss: 0.4075 - val_accuracy: 0.8698\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4950 - accuracy: 0.8454 - val_loss: 0.3945 - val_accuracy: 0.8698\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.5431 - accuracy: 0.8207 - val_loss: 0.4303 - val_accuracy: 0.8558\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4139 - accuracy: 0.8624 - val_loss: 0.4381 - val_accuracy: 0.8512\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4446 - accuracy: 0.8686 - val_loss: 0.4123 - val_accuracy: 0.8744\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4592 - accuracy: 0.8362 - val_loss: 0.4275 - val_accuracy: 0.8651\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4685 - accuracy: 0.8423 - val_loss: 0.4003 - val_accuracy: 0.8558\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3993 - accuracy: 0.8563 - val_loss: 0.4261 - val_accuracy: 0.8558\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3900 - accuracy: 0.8655 - val_loss: 0.3723 - val_accuracy: 0.8791\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4367 - accuracy: 0.8640 - val_loss: 0.3949 - val_accuracy: 0.8791\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4050 - accuracy: 0.8609 - val_loss: 0.4621 - val_accuracy: 0.8605\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.3972 - accuracy: 0.8640 - val_loss: 0.3881 - val_accuracy: 0.8977\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.3902 - accuracy: 0.8717 - val_loss: 0.3833 - val_accuracy: 0.8698\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4109 - accuracy: 0.8624 - val_loss: 0.4071 - val_accuracy: 0.8837\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4537 - accuracy: 0.8470 - val_loss: 0.4161 - val_accuracy: 0.8698\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3787 - accuracy: 0.8702 - val_loss: 0.3775 - val_accuracy: 0.8605\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3432 - accuracy: 0.8872 - val_loss: 0.3514 - val_accuracy: 0.8884\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3237 - accuracy: 0.8949 - val_loss: 0.3787 - val_accuracy: 0.8698\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3336 - accuracy: 0.8918 - val_loss: 0.4162 - val_accuracy: 0.8837\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3994 - accuracy: 0.8841 - val_loss: 0.3602 - val_accuracy: 0.8837\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3131 - accuracy: 0.9026 - val_loss: 0.3822 - val_accuracy: 0.8698\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3639 - accuracy: 0.8887 - val_loss: 0.3354 - val_accuracy: 0.8930\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3394 - accuracy: 0.8887 - val_loss: 0.3622 - val_accuracy: 0.8837\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3272 - accuracy: 0.8841 - val_loss: 0.3708 - val_accuracy: 0.8884\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.3061 - accuracy: 0.8995 - val_loss: 0.3708 - val_accuracy: 0.8884\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3367 - accuracy: 0.8949 - val_loss: 0.4119 - val_accuracy: 0.8744\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3184 - accuracy: 0.8949 - val_loss: 0.3919 - val_accuracy: 0.8698\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.3295 - accuracy: 0.8949 - val_loss: 0.3703 - val_accuracy: 0.8837\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.2795 - accuracy: 0.9104 - val_loss: 0.3682 - val_accuracy: 0.8744\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.3033 - accuracy: 0.8964 - val_loss: 0.3464 - val_accuracy: 0.8884\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.3126 - accuracy: 0.9042 - val_loss: 0.3651 - val_accuracy: 0.8837\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 2s 41ms/step - loss: 0.2949 - accuracy: 0.9150 - val_loss: 0.3434 - val_accuracy: 0.9023\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.2842 - accuracy: 0.9057 - val_loss: 0.3520 - val_accuracy: 0.8977\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.2889 - accuracy: 0.9073 - val_loss: 0.4027 - val_accuracy: 0.8977\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2668 - accuracy: 0.9196 - val_loss: 0.3264 - val_accuracy: 0.9070\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2472 - accuracy: 0.9181 - val_loss: 0.4193 - val_accuracy: 0.8884\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.2577 - accuracy: 0.9243 - val_loss: 0.4012 - val_accuracy: 0.8837\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.2502 - accuracy: 0.9212 - val_loss: 0.4778 - val_accuracy: 0.8884\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.2508 - accuracy: 0.9274 - val_loss: 0.3410 - val_accuracy: 0.8977\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2313 - accuracy: 0.9335 - val_loss: 0.3330 - val_accuracy: 0.9023\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2681 - accuracy: 0.9227 - val_loss: 0.3295 - val_accuracy: 0.9070\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2729 - accuracy: 0.9088 - val_loss: 0.4144 - val_accuracy: 0.8977\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2627 - accuracy: 0.9057 - val_loss: 0.3629 - val_accuracy: 0.9209\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2351 - accuracy: 0.9351 - val_loss: 0.3364 - val_accuracy: 0.9070\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2906 - accuracy: 0.9042 - val_loss: 0.3971 - val_accuracy: 0.8930\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2058 - accuracy: 0.9413 - val_loss: 0.3301 - val_accuracy: 0.9116\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2171 - accuracy: 0.9413 - val_loss: 0.3543 - val_accuracy: 0.8977\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2271 - accuracy: 0.9459 - val_loss: 0.3809 - val_accuracy: 0.9070\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.2370 - accuracy: 0.9304 - val_loss: 0.3848 - val_accuracy: 0.8930\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2117 - accuracy: 0.9521 - val_loss: 0.3619 - val_accuracy: 0.8977\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2323 - accuracy: 0.9304 - val_loss: 0.3488 - val_accuracy: 0.9070\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2082 - accuracy: 0.9366 - val_loss: 0.3524 - val_accuracy: 0.9070\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1892 - accuracy: 0.9505 - val_loss: 0.3166 - val_accuracy: 0.9256\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1812 - accuracy: 0.9552 - val_loss: 0.3427 - val_accuracy: 0.9116\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2048 - accuracy: 0.9366 - val_loss: 0.3066 - val_accuracy: 0.9256\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1814 - accuracy: 0.9521 - val_loss: 0.3344 - val_accuracy: 0.9070\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1931 - accuracy: 0.9552 - val_loss: 0.3320 - val_accuracy: 0.9116\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.1502 - accuracy: 0.9691 - val_loss: 0.3199 - val_accuracy: 0.9163\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1987 - accuracy: 0.9490 - val_loss: 0.3922 - val_accuracy: 0.9070\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1949 - accuracy: 0.9521 - val_loss: 0.3804 - val_accuracy: 0.9070\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1755 - accuracy: 0.9505 - val_loss: 0.3370 - val_accuracy: 0.9023\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1708 - accuracy: 0.9567 - val_loss: 0.3783 - val_accuracy: 0.9163\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1445 - accuracy: 0.9645 - val_loss: 0.3372 - val_accuracy: 0.9302\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1339 - accuracy: 0.9722 - val_loss: 0.3146 - val_accuracy: 0.9163\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1821 - accuracy: 0.9474 - val_loss: 0.3453 - val_accuracy: 0.9116\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1567 - accuracy: 0.9614 - val_loss: 0.3451 - val_accuracy: 0.9302\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.1273 - accuracy: 0.9722 - val_loss: 0.3693 - val_accuracy: 0.9116\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1441 - accuracy: 0.9660 - val_loss: 0.3404 - val_accuracy: 0.9163\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1660 - accuracy: 0.9629 - val_loss: 0.3534 - val_accuracy: 0.9163\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1378 - accuracy: 0.9645 - val_loss: 0.3729 - val_accuracy: 0.9163\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1430 - accuracy: 0.9784 - val_loss: 0.3497 - val_accuracy: 0.9163\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1428 - accuracy: 0.9784 - val_loss: 0.3185 - val_accuracy: 0.9209\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1440 - accuracy: 0.9691 - val_loss: 0.4126 - val_accuracy: 0.9070\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1614 - accuracy: 0.9583 - val_loss: 0.3123 - val_accuracy: 0.9209\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1263 - accuracy: 0.9753 - val_loss: 0.3142 - val_accuracy: 0.9209\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1607 - accuracy: 0.9536 - val_loss: 0.3674 - val_accuracy: 0.9116\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1341 - accuracy: 0.9706 - val_loss: 0.3707 - val_accuracy: 0.9163\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1541 - accuracy: 0.9614 - val_loss: 0.3567 - val_accuracy: 0.9256\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1642 - accuracy: 0.9583 - val_loss: 0.3038 - val_accuracy: 0.9163\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1445 - accuracy: 0.9614 - val_loss: 0.3060 - val_accuracy: 0.9209\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1141 - accuracy: 0.9768 - val_loss: 0.3654 - val_accuracy: 0.9209\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1413 - accuracy: 0.9645 - val_loss: 0.3835 - val_accuracy: 0.9163\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1316 - accuracy: 0.9691 - val_loss: 0.3789 - val_accuracy: 0.9209\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1494 - accuracy: 0.9706 - val_loss: 0.3702 - val_accuracy: 0.9209\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.1211 - accuracy: 0.9768 - val_loss: 0.3592 - val_accuracy: 0.9302\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1538 - accuracy: 0.9583 - val_loss: 0.3637 - val_accuracy: 0.9256\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1508 - accuracy: 0.9598 - val_loss: 0.3781 - val_accuracy: 0.9302\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 1s 37ms/step - loss: 0.1299 - accuracy: 0.9753 - val_loss: 0.3711 - val_accuracy: 0.9256\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.1324 - accuracy: 0.9722 - val_loss: 0.3633 - val_accuracy: 0.9256\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.1042 - accuracy: 0.9830 - val_loss: 0.3727 - val_accuracy: 0.9256\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1257 - accuracy: 0.9722 - val_loss: 0.3964 - val_accuracy: 0.9209\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.1143 - accuracy: 0.9737 - val_loss: 0.3476 - val_accuracy: 0.9302\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.1136 - accuracy: 0.9768 - val_loss: 0.3713 - val_accuracy: 0.9302\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1058 - accuracy: 0.9753 - val_loss: 0.3537 - val_accuracy: 0.9163\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1087 - accuracy: 0.9737 - val_loss: 0.4095 - val_accuracy: 0.9116\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1220 - accuracy: 0.9706 - val_loss: 0.3664 - val_accuracy: 0.9256\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1566 - accuracy: 0.9629 - val_loss: 0.3598 - val_accuracy: 0.9209\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1113 - accuracy: 0.9753 - val_loss: 0.3807 - val_accuracy: 0.9116\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0959 - accuracy: 0.9845 - val_loss: 0.3432 - val_accuracy: 0.9256\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0826 - accuracy: 0.9954 - val_loss: 0.3627 - val_accuracy: 0.9209\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0958 - accuracy: 0.9845 - val_loss: 0.4139 - val_accuracy: 0.9116\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1290 - accuracy: 0.9691 - val_loss: 0.4641 - val_accuracy: 0.9023\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1122 - accuracy: 0.9784 - val_loss: 0.3398 - val_accuracy: 0.9256\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1127 - accuracy: 0.9799 - val_loss: 0.3612 - val_accuracy: 0.9256\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1141 - accuracy: 0.9784 - val_loss: 0.3887 - val_accuracy: 0.9256\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1160 - accuracy: 0.9784 - val_loss: 0.2962 - val_accuracy: 0.9488\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0896 - accuracy: 0.9861 - val_loss: 0.3219 - val_accuracy: 0.9395\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0934 - accuracy: 0.9830 - val_loss: 0.3529 - val_accuracy: 0.9302\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.1035 - accuracy: 0.9815 - val_loss: 0.3937 - val_accuracy: 0.9256\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1191 - accuracy: 0.9753 - val_loss: 0.3895 - val_accuracy: 0.9256\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1261 - accuracy: 0.9706 - val_loss: 0.3942 - val_accuracy: 0.9256\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1118 - accuracy: 0.9784 - val_loss: 0.3588 - val_accuracy: 0.9209\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1148 - accuracy: 0.9768 - val_loss: 0.3554 - val_accuracy: 0.9302\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1174 - accuracy: 0.9737 - val_loss: 0.3394 - val_accuracy: 0.9302\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1019 - accuracy: 0.9830 - val_loss: 0.3500 - val_accuracy: 0.9302\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0974 - accuracy: 0.9892 - val_loss: 0.3546 - val_accuracy: 0.9349\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1092 - accuracy: 0.9784 - val_loss: 0.3669 - val_accuracy: 0.9349\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0975 - accuracy: 0.9861 - val_loss: 0.3889 - val_accuracy: 0.9302\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0728 - accuracy: 0.9954 - val_loss: 0.3706 - val_accuracy: 0.9209\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.1027 - accuracy: 0.9799 - val_loss: 0.3518 - val_accuracy: 0.9302\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0902 - accuracy: 0.9876 - val_loss: 0.3656 - val_accuracy: 0.9163\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0995 - accuracy: 0.9830 - val_loss: 0.3337 - val_accuracy: 0.9349\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0876 - accuracy: 0.9923 - val_loss: 0.3826 - val_accuracy: 0.9302\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0998 - accuracy: 0.9830 - val_loss: 0.4006 - val_accuracy: 0.9256\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0956 - accuracy: 0.9861 - val_loss: 0.4107 - val_accuracy: 0.9349\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0873 - accuracy: 0.9876 - val_loss: 0.4050 - val_accuracy: 0.9302\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.1295 - accuracy: 0.9753 - val_loss: 0.3886 - val_accuracy: 0.9163\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0886 - accuracy: 0.9830 - val_loss: 0.3841 - val_accuracy: 0.9256\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0731 - accuracy: 0.9938 - val_loss: 0.3490 - val_accuracy: 0.9302\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0935 - accuracy: 0.9861 - val_loss: 0.3920 - val_accuracy: 0.9163\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0875 - accuracy: 0.9907 - val_loss: 0.3626 - val_accuracy: 0.9349\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0772 - accuracy: 0.9907 - val_loss: 0.4383 - val_accuracy: 0.9302\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0823 - accuracy: 0.9907 - val_loss: 0.4143 - val_accuracy: 0.9163\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1180 - accuracy: 0.9737 - val_loss: 0.4024 - val_accuracy: 0.9209\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0828 - accuracy: 0.9907 - val_loss: 0.3766 - val_accuracy: 0.9256\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1009 - accuracy: 0.9861 - val_loss: 0.3668 - val_accuracy: 0.9256\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0694 - accuracy: 0.9938 - val_loss: 0.3753 - val_accuracy: 0.9302\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0797 - accuracy: 0.9876 - val_loss: 0.3996 - val_accuracy: 0.9302\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0761 - accuracy: 0.9892 - val_loss: 0.3470 - val_accuracy: 0.9395\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0747 - accuracy: 0.9938 - val_loss: 0.4136 - val_accuracy: 0.9349\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1097 - accuracy: 0.9815 - val_loss: 0.3407 - val_accuracy: 0.9302\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0908 - accuracy: 0.9845 - val_loss: 0.3804 - val_accuracy: 0.9256\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0956 - accuracy: 0.9815 - val_loss: 0.3882 - val_accuracy: 0.9349\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0768 - accuracy: 0.9907 - val_loss: 0.3747 - val_accuracy: 0.9302\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0970 - accuracy: 0.9861 - val_loss: 0.4275 - val_accuracy: 0.9163\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0822 - accuracy: 0.9876 - val_loss: 0.3715 - val_accuracy: 0.9302\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0836 - accuracy: 0.9892 - val_loss: 0.3793 - val_accuracy: 0.9349\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0842 - accuracy: 0.9876 - val_loss: 0.4258 - val_accuracy: 0.9256\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 2s 43ms/step - loss: 0.0873 - accuracy: 0.9845 - val_loss: 0.3923 - val_accuracy: 0.9349\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 2s 45ms/step - loss: 0.0727 - accuracy: 0.9938 - val_loss: 0.3805 - val_accuracy: 0.9302\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0708 - accuracy: 0.9907 - val_loss: 0.4214 - val_accuracy: 0.9349\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.0878 - accuracy: 0.9876 - val_loss: 0.4396 - val_accuracy: 0.9302\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0980 - accuracy: 0.9861 - val_loss: 0.4205 - val_accuracy: 0.9163\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0984 - accuracy: 0.9861 - val_loss: 0.4008 - val_accuracy: 0.9302\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0760 - accuracy: 0.9907 - val_loss: 0.3684 - val_accuracy: 0.9349\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0930 - accuracy: 0.9876 - val_loss: 0.3605 - val_accuracy: 0.9349\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0820 - accuracy: 0.9938 - val_loss: 0.3750 - val_accuracy: 0.9256\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0990 - accuracy: 0.9737 - val_loss: 0.3706 - val_accuracy: 0.9302\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0770 - accuracy: 0.9923 - val_loss: 0.4249 - val_accuracy: 0.9302\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0767 - accuracy: 0.9923 - val_loss: 0.3885 - val_accuracy: 0.9302\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0784 - accuracy: 0.9861 - val_loss: 0.4833 - val_accuracy: 0.9209\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0946 - accuracy: 0.9845 - val_loss: 0.4195 - val_accuracy: 0.9070\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0866 - accuracy: 0.9892 - val_loss: 0.4146 - val_accuracy: 0.9163\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0841 - accuracy: 0.9845 - val_loss: 0.3994 - val_accuracy: 0.9302\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0827 - accuracy: 0.9907 - val_loss: 0.3752 - val_accuracy: 0.9163\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0986 - accuracy: 0.9830 - val_loss: 0.3761 - val_accuracy: 0.9349\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0875 - accuracy: 0.9861 - val_loss: 0.3609 - val_accuracy: 0.9256\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0905 - accuracy: 0.9907 - val_loss: 0.4049 - val_accuracy: 0.9209\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1016 - accuracy: 0.9876 - val_loss: 0.3846 - val_accuracy: 0.9256\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0658 - accuracy: 0.9969 - val_loss: 0.3697 - val_accuracy: 0.9256\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0926 - accuracy: 0.9907 - val_loss: 0.4273 - val_accuracy: 0.9070\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0904 - accuracy: 0.9876 - val_loss: 0.3872 - val_accuracy: 0.9256\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0811 - accuracy: 0.9861 - val_loss: 0.4621 - val_accuracy: 0.9070\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0800 - accuracy: 0.9923 - val_loss: 0.4683 - val_accuracy: 0.9209\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0699 - accuracy: 0.9938 - val_loss: 0.3912 - val_accuracy: 0.9256\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0639 - accuracy: 0.9969 - val_loss: 0.3792 - val_accuracy: 0.9302\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0784 - accuracy: 0.9938 - val_loss: 0.3675 - val_accuracy: 0.9302\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0841 - accuracy: 0.9907 - val_loss: 0.3986 - val_accuracy: 0.9209\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0728 - accuracy: 0.9892 - val_loss: 0.4330 - val_accuracy: 0.9256\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0769 - accuracy: 0.9907 - val_loss: 0.3787 - val_accuracy: 0.9023\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0898 - accuracy: 0.9845 - val_loss: 0.4127 - val_accuracy: 0.9256\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0867 - accuracy: 0.9907 - val_loss: 0.3825 - val_accuracy: 0.9302\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0707 - accuracy: 0.9938 - val_loss: 0.3913 - val_accuracy: 0.9302\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0797 - accuracy: 0.9923 - val_loss: 0.4348 - val_accuracy: 0.9163\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0766 - accuracy: 0.9892 - val_loss: 0.4224 - val_accuracy: 0.9209\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0861 - accuracy: 0.9876 - val_loss: 0.3679 - val_accuracy: 0.9302\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9349\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0832 - accuracy: 0.9892 - val_loss: 0.4455 - val_accuracy: 0.8977\n",
      "21/21 [==============================] - 2s 10ms/step\n",
      "7/7 [==============================] - 0s 12ms/step\n",
      "Epoch 1/200\n",
      "41/41 [==============================] - 17s 82ms/step - loss: 1.1565 - accuracy: 0.6121 - val_loss: 0.6079 - val_accuracy: 0.7953\n",
      "Epoch 2/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.7789 - accuracy: 0.7512 - val_loss: 0.4350 - val_accuracy: 0.8465\n",
      "Epoch 3/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.7577 - accuracy: 0.7589 - val_loss: 0.4494 - val_accuracy: 0.8651\n",
      "Epoch 4/200\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.6399 - accuracy: 0.7913 - val_loss: 0.4397 - val_accuracy: 0.8651\n",
      "Epoch 5/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.5433 - accuracy: 0.8300 - val_loss: 0.3654 - val_accuracy: 0.8884\n",
      "Epoch 6/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.6166 - accuracy: 0.7944 - val_loss: 0.4246 - val_accuracy: 0.8744\n",
      "Epoch 7/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.5719 - accuracy: 0.8176 - val_loss: 0.4131 - val_accuracy: 0.8558\n",
      "Epoch 8/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.5772 - accuracy: 0.8269 - val_loss: 0.4127 - val_accuracy: 0.8558\n",
      "Epoch 9/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.5535 - accuracy: 0.8207 - val_loss: 0.3872 - val_accuracy: 0.8791\n",
      "Epoch 10/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.5013 - accuracy: 0.8238 - val_loss: 0.4027 - val_accuracy: 0.8744\n",
      "Epoch 11/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.4963 - accuracy: 0.8408 - val_loss: 0.3855 - val_accuracy: 0.8698\n",
      "Epoch 12/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.5180 - accuracy: 0.8192 - val_loss: 0.3934 - val_accuracy: 0.8605\n",
      "Epoch 13/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.5410 - accuracy: 0.8053 - val_loss: 0.3875 - val_accuracy: 0.8651\n",
      "Epoch 14/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.4835 - accuracy: 0.8300 - val_loss: 0.3557 - val_accuracy: 0.8744\n",
      "Epoch 15/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.4433 - accuracy: 0.8578 - val_loss: 0.4004 - val_accuracy: 0.8651\n",
      "Epoch 16/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4783 - accuracy: 0.8439 - val_loss: 0.3643 - val_accuracy: 0.8977\n",
      "Epoch 17/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.5119 - accuracy: 0.8346 - val_loss: 0.3445 - val_accuracy: 0.8791\n",
      "Epoch 18/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3804 - accuracy: 0.8702 - val_loss: 0.3573 - val_accuracy: 0.8791\n",
      "Epoch 19/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.4001 - accuracy: 0.8686 - val_loss: 0.3812 - val_accuracy: 0.8884\n",
      "Epoch 20/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4246 - accuracy: 0.8594 - val_loss: 0.3399 - val_accuracy: 0.9070\n",
      "Epoch 21/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4429 - accuracy: 0.8485 - val_loss: 0.3787 - val_accuracy: 0.8930\n",
      "Epoch 22/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3816 - accuracy: 0.8733 - val_loss: 0.3706 - val_accuracy: 0.8651\n",
      "Epoch 23/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3942 - accuracy: 0.8671 - val_loss: 0.3402 - val_accuracy: 0.9023\n",
      "Epoch 24/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.4229 - accuracy: 0.8655 - val_loss: 0.3760 - val_accuracy: 0.8605\n",
      "Epoch 25/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3767 - accuracy: 0.8856 - val_loss: 0.3248 - val_accuracy: 0.8930\n",
      "Epoch 26/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3517 - accuracy: 0.8934 - val_loss: 0.3469 - val_accuracy: 0.8930\n",
      "Epoch 27/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3390 - accuracy: 0.9011 - val_loss: 0.3325 - val_accuracy: 0.8837\n",
      "Epoch 28/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3262 - accuracy: 0.8903 - val_loss: 0.3289 - val_accuracy: 0.8930\n",
      "Epoch 29/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3416 - accuracy: 0.8918 - val_loss: 0.3218 - val_accuracy: 0.8744\n",
      "Epoch 30/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3184 - accuracy: 0.8872 - val_loss: 0.3790 - val_accuracy: 0.8744\n",
      "Epoch 31/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.4359 - accuracy: 0.8671 - val_loss: 0.3627 - val_accuracy: 0.8930\n",
      "Epoch 32/200\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.3073 - accuracy: 0.9042 - val_loss: 0.3029 - val_accuracy: 0.8977\n",
      "Epoch 33/200\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 0.3145 - accuracy: 0.9057 - val_loss: 0.3482 - val_accuracy: 0.8930\n",
      "Epoch 34/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3140 - accuracy: 0.9042 - val_loss: 0.3323 - val_accuracy: 0.8930\n",
      "Epoch 35/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3365 - accuracy: 0.8903 - val_loss: 0.3013 - val_accuracy: 0.8930\n",
      "Epoch 36/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2744 - accuracy: 0.9150 - val_loss: 0.3206 - val_accuracy: 0.8930\n",
      "Epoch 37/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2888 - accuracy: 0.8995 - val_loss: 0.3197 - val_accuracy: 0.9023\n",
      "Epoch 38/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2559 - accuracy: 0.9196 - val_loss: 0.3137 - val_accuracy: 0.8977\n",
      "Epoch 39/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.3182 - accuracy: 0.8887 - val_loss: 0.3243 - val_accuracy: 0.8930\n",
      "Epoch 40/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.3013 - accuracy: 0.9057 - val_loss: 0.3177 - val_accuracy: 0.8977\n",
      "Epoch 41/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.2627 - accuracy: 0.9243 - val_loss: 0.3205 - val_accuracy: 0.9163\n",
      "Epoch 42/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2769 - accuracy: 0.9119 - val_loss: 0.2971 - val_accuracy: 0.8977\n",
      "Epoch 43/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2706 - accuracy: 0.9150 - val_loss: 0.3031 - val_accuracy: 0.9023\n",
      "Epoch 44/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2587 - accuracy: 0.9274 - val_loss: 0.3063 - val_accuracy: 0.9116\n",
      "Epoch 45/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2393 - accuracy: 0.9243 - val_loss: 0.3035 - val_accuracy: 0.9023\n",
      "Epoch 46/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2409 - accuracy: 0.9289 - val_loss: 0.2943 - val_accuracy: 0.9163\n",
      "Epoch 47/200\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.2485 - accuracy: 0.9382 - val_loss: 0.3100 - val_accuracy: 0.9116\n",
      "Epoch 48/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.2644 - accuracy: 0.9196 - val_loss: 0.3165 - val_accuracy: 0.9070\n",
      "Epoch 49/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.2878 - accuracy: 0.9088 - val_loss: 0.3246 - val_accuracy: 0.9163\n",
      "Epoch 50/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.2526 - accuracy: 0.9243 - val_loss: 0.3366 - val_accuracy: 0.9023\n",
      "Epoch 51/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.2459 - accuracy: 0.9258 - val_loss: 0.2977 - val_accuracy: 0.8930\n",
      "Epoch 52/200\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 0.2166 - accuracy: 0.9413 - val_loss: 0.2940 - val_accuracy: 0.9116\n",
      "Epoch 53/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.2361 - accuracy: 0.9258 - val_loss: 0.3279 - val_accuracy: 0.8884\n",
      "Epoch 54/200\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.2384 - accuracy: 0.9274 - val_loss: 0.2874 - val_accuracy: 0.9163\n",
      "Epoch 55/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2339 - accuracy: 0.9366 - val_loss: 0.3324 - val_accuracy: 0.9070\n",
      "Epoch 56/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2463 - accuracy: 0.9196 - val_loss: 0.3041 - val_accuracy: 0.9302\n",
      "Epoch 57/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1842 - accuracy: 0.9536 - val_loss: 0.3289 - val_accuracy: 0.9163\n",
      "Epoch 58/200\n",
      "41/41 [==============================] - 1s 32ms/step - loss: 0.1847 - accuracy: 0.9552 - val_loss: 0.3043 - val_accuracy: 0.9163\n",
      "Epoch 59/200\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.1852 - accuracy: 0.9474 - val_loss: 0.2942 - val_accuracy: 0.9349\n",
      "Epoch 60/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1851 - accuracy: 0.9490 - val_loss: 0.2946 - val_accuracy: 0.9209\n",
      "Epoch 61/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.2013 - accuracy: 0.9413 - val_loss: 0.2591 - val_accuracy: 0.9116\n",
      "Epoch 62/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1678 - accuracy: 0.9505 - val_loss: 0.2893 - val_accuracy: 0.9209\n",
      "Epoch 63/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.2185 - accuracy: 0.9459 - val_loss: 0.3306 - val_accuracy: 0.9070\n",
      "Epoch 64/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1978 - accuracy: 0.9397 - val_loss: 0.2903 - val_accuracy: 0.9070\n",
      "Epoch 65/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1912 - accuracy: 0.9474 - val_loss: 0.3262 - val_accuracy: 0.9163\n",
      "Epoch 66/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.2257 - accuracy: 0.9274 - val_loss: 0.2600 - val_accuracy: 0.9395\n",
      "Epoch 67/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1516 - accuracy: 0.9598 - val_loss: 0.2741 - val_accuracy: 0.9349\n",
      "Epoch 68/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1349 - accuracy: 0.9706 - val_loss: 0.2901 - val_accuracy: 0.9302\n",
      "Epoch 69/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1817 - accuracy: 0.9490 - val_loss: 0.2979 - val_accuracy: 0.9116\n",
      "Epoch 70/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1572 - accuracy: 0.9645 - val_loss: 0.2839 - val_accuracy: 0.9256\n",
      "Epoch 71/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1466 - accuracy: 0.9706 - val_loss: 0.2690 - val_accuracy: 0.9302\n",
      "Epoch 72/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1670 - accuracy: 0.9552 - val_loss: 0.3028 - val_accuracy: 0.9209\n",
      "Epoch 73/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1734 - accuracy: 0.9490 - val_loss: 0.2709 - val_accuracy: 0.9256\n",
      "Epoch 74/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1652 - accuracy: 0.9629 - val_loss: 0.3528 - val_accuracy: 0.9209\n",
      "Epoch 75/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.1741 - accuracy: 0.9583 - val_loss: 0.3040 - val_accuracy: 0.9209\n",
      "Epoch 76/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1394 - accuracy: 0.9722 - val_loss: 0.2861 - val_accuracy: 0.9209\n",
      "Epoch 77/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1521 - accuracy: 0.9645 - val_loss: 0.2972 - val_accuracy: 0.9256\n",
      "Epoch 78/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1370 - accuracy: 0.9722 - val_loss: 0.2623 - val_accuracy: 0.9302\n",
      "Epoch 79/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1646 - accuracy: 0.9598 - val_loss: 0.2753 - val_accuracy: 0.9302\n",
      "Epoch 80/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1298 - accuracy: 0.9737 - val_loss: 0.2851 - val_accuracy: 0.9209\n",
      "Epoch 81/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1342 - accuracy: 0.9737 - val_loss: 0.2483 - val_accuracy: 0.9395\n",
      "Epoch 82/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1309 - accuracy: 0.9706 - val_loss: 0.2666 - val_accuracy: 0.9163\n",
      "Epoch 83/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1400 - accuracy: 0.9660 - val_loss: 0.3041 - val_accuracy: 0.9209\n",
      "Epoch 84/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.1466 - accuracy: 0.9660 - val_loss: 0.2810 - val_accuracy: 0.9256\n",
      "Epoch 85/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1569 - accuracy: 0.9583 - val_loss: 0.2841 - val_accuracy: 0.9302\n",
      "Epoch 86/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1635 - accuracy: 0.9583 - val_loss: 0.3024 - val_accuracy: 0.9302\n",
      "Epoch 87/200\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.1505 - accuracy: 0.9629 - val_loss: 0.2807 - val_accuracy: 0.9116\n",
      "Epoch 88/200\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.1189 - accuracy: 0.9799 - val_loss: 0.3923 - val_accuracy: 0.9070\n",
      "Epoch 89/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1350 - accuracy: 0.9691 - val_loss: 0.2766 - val_accuracy: 0.9302\n",
      "Epoch 90/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1136 - accuracy: 0.9799 - val_loss: 0.2942 - val_accuracy: 0.9163\n",
      "Epoch 91/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1460 - accuracy: 0.9660 - val_loss: 0.2661 - val_accuracy: 0.9302\n",
      "Epoch 92/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1143 - accuracy: 0.9768 - val_loss: 0.2991 - val_accuracy: 0.9163\n",
      "Epoch 93/200\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.1616 - accuracy: 0.9753 - val_loss: 0.3100 - val_accuracy: 0.9256\n",
      "Epoch 94/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1407 - accuracy: 0.9706 - val_loss: 0.3225 - val_accuracy: 0.9256\n",
      "Epoch 95/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1515 - accuracy: 0.9614 - val_loss: 0.3225 - val_accuracy: 0.9116\n",
      "Epoch 96/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1656 - accuracy: 0.9614 - val_loss: 0.3134 - val_accuracy: 0.9209\n",
      "Epoch 97/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1468 - accuracy: 0.9645 - val_loss: 0.3172 - val_accuracy: 0.9256\n",
      "Epoch 98/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1396 - accuracy: 0.9753 - val_loss: 0.3067 - val_accuracy: 0.9395\n",
      "Epoch 99/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1449 - accuracy: 0.9722 - val_loss: 0.3179 - val_accuracy: 0.9256\n",
      "Epoch 100/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1181 - accuracy: 0.9753 - val_loss: 0.2782 - val_accuracy: 0.9163\n",
      "Epoch 101/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0988 - accuracy: 0.9815 - val_loss: 0.2903 - val_accuracy: 0.9349\n",
      "Epoch 102/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1198 - accuracy: 0.9737 - val_loss: 0.3154 - val_accuracy: 0.9256\n",
      "Epoch 103/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1120 - accuracy: 0.9815 - val_loss: 0.2777 - val_accuracy: 0.9349\n",
      "Epoch 104/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1308 - accuracy: 0.9645 - val_loss: 0.2961 - val_accuracy: 0.9256\n",
      "Epoch 105/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1223 - accuracy: 0.9753 - val_loss: 0.3139 - val_accuracy: 0.9349\n",
      "Epoch 106/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0965 - accuracy: 0.9830 - val_loss: 0.2828 - val_accuracy: 0.9395\n",
      "Epoch 107/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1264 - accuracy: 0.9784 - val_loss: 0.3179 - val_accuracy: 0.9302\n",
      "Epoch 108/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1205 - accuracy: 0.9799 - val_loss: 0.3263 - val_accuracy: 0.9256\n",
      "Epoch 109/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.1121 - accuracy: 0.9737 - val_loss: 0.2924 - val_accuracy: 0.9349\n",
      "Epoch 110/200\n",
      "41/41 [==============================] - 2s 40ms/step - loss: 0.1126 - accuracy: 0.9799 - val_loss: 0.2985 - val_accuracy: 0.9302\n",
      "Epoch 111/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1209 - accuracy: 0.9722 - val_loss: 0.2915 - val_accuracy: 0.9395\n",
      "Epoch 112/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.1087 - accuracy: 0.9784 - val_loss: 0.3206 - val_accuracy: 0.9256\n",
      "Epoch 113/200\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.1314 - accuracy: 0.9691 - val_loss: 0.3042 - val_accuracy: 0.9302\n",
      "Epoch 114/200\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 0.1152 - accuracy: 0.9830 - val_loss: 0.3035 - val_accuracy: 0.9256\n",
      "Epoch 115/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.1041 - accuracy: 0.9799 - val_loss: 0.3089 - val_accuracy: 0.9349\n",
      "Epoch 116/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1254 - accuracy: 0.9691 - val_loss: 0.2901 - val_accuracy: 0.9395\n",
      "Epoch 117/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.1161 - accuracy: 0.9753 - val_loss: 0.3545 - val_accuracy: 0.9302\n",
      "Epoch 118/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1137 - accuracy: 0.9784 - val_loss: 0.3375 - val_accuracy: 0.9163\n",
      "Epoch 119/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1270 - accuracy: 0.9737 - val_loss: 0.3402 - val_accuracy: 0.9302\n",
      "Epoch 120/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1014 - accuracy: 0.9845 - val_loss: 0.3375 - val_accuracy: 0.9302\n",
      "Epoch 121/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1194 - accuracy: 0.9815 - val_loss: 0.3286 - val_accuracy: 0.9163\n",
      "Epoch 122/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1211 - accuracy: 0.9753 - val_loss: 0.3225 - val_accuracy: 0.9209\n",
      "Epoch 123/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0925 - accuracy: 0.9876 - val_loss: 0.3142 - val_accuracy: 0.9256\n",
      "Epoch 124/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1074 - accuracy: 0.9861 - val_loss: 0.3001 - val_accuracy: 0.9395\n",
      "Epoch 125/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0832 - accuracy: 0.9923 - val_loss: 0.3060 - val_accuracy: 0.9349\n",
      "Epoch 126/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0970 - accuracy: 0.9845 - val_loss: 0.2949 - val_accuracy: 0.9349\n",
      "Epoch 127/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0845 - accuracy: 0.9861 - val_loss: 0.2779 - val_accuracy: 0.9349\n",
      "Epoch 128/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.1291 - accuracy: 0.9737 - val_loss: 0.3145 - val_accuracy: 0.9349\n",
      "Epoch 129/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0963 - accuracy: 0.9861 - val_loss: 0.2969 - val_accuracy: 0.9442\n",
      "Epoch 130/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1122 - accuracy: 0.9768 - val_loss: 0.2854 - val_accuracy: 0.9395\n",
      "Epoch 131/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0967 - accuracy: 0.9892 - val_loss: 0.3597 - val_accuracy: 0.9256\n",
      "Epoch 132/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0842 - accuracy: 0.9907 - val_loss: 0.3144 - val_accuracy: 0.9395\n",
      "Epoch 133/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0909 - accuracy: 0.9892 - val_loss: 0.3109 - val_accuracy: 0.9442\n",
      "Epoch 134/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0917 - accuracy: 0.9861 - val_loss: 0.3224 - val_accuracy: 0.9256\n",
      "Epoch 135/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1005 - accuracy: 0.9815 - val_loss: 0.3312 - val_accuracy: 0.9209\n",
      "Epoch 136/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0951 - accuracy: 0.9830 - val_loss: 0.3214 - val_accuracy: 0.9349\n",
      "Epoch 137/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1070 - accuracy: 0.9768 - val_loss: 0.3206 - val_accuracy: 0.9349\n",
      "Epoch 138/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1033 - accuracy: 0.9830 - val_loss: 0.3570 - val_accuracy: 0.9256\n",
      "Epoch 139/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0802 - accuracy: 0.9923 - val_loss: 0.3235 - val_accuracy: 0.9302\n",
      "Epoch 140/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.1079 - accuracy: 0.9815 - val_loss: 0.2732 - val_accuracy: 0.9442\n",
      "Epoch 141/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0946 - accuracy: 0.9861 - val_loss: 0.2958 - val_accuracy: 0.9302\n",
      "Epoch 142/200\n",
      "41/41 [==============================] - 2s 42ms/step - loss: 0.0782 - accuracy: 0.9923 - val_loss: 0.3001 - val_accuracy: 0.9442\n",
      "Epoch 143/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0740 - accuracy: 0.9923 - val_loss: 0.3050 - val_accuracy: 0.9349\n",
      "Epoch 144/200\n",
      "41/41 [==============================] - 1s 31ms/step - loss: 0.0841 - accuracy: 0.9876 - val_loss: 0.3048 - val_accuracy: 0.9349\n",
      "Epoch 145/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0858 - accuracy: 0.9861 - val_loss: 0.3214 - val_accuracy: 0.9349\n",
      "Epoch 146/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0802 - accuracy: 0.9907 - val_loss: 0.3337 - val_accuracy: 0.9302\n",
      "Epoch 147/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0847 - accuracy: 0.9923 - val_loss: 0.3044 - val_accuracy: 0.9302\n",
      "Epoch 148/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0911 - accuracy: 0.9954 - val_loss: 0.3374 - val_accuracy: 0.9302\n",
      "Epoch 149/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0979 - accuracy: 0.9830 - val_loss: 0.3301 - val_accuracy: 0.9302\n",
      "Epoch 150/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0910 - accuracy: 0.9861 - val_loss: 0.3570 - val_accuracy: 0.9302\n",
      "Epoch 151/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0826 - accuracy: 0.9845 - val_loss: 0.3212 - val_accuracy: 0.9302\n",
      "Epoch 152/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0961 - accuracy: 0.9861 - val_loss: 0.3365 - val_accuracy: 0.9116\n",
      "Epoch 153/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0805 - accuracy: 0.9923 - val_loss: 0.3322 - val_accuracy: 0.9209\n",
      "Epoch 154/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0765 - accuracy: 0.9907 - val_loss: 0.3032 - val_accuracy: 0.9395\n",
      "Epoch 155/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0920 - accuracy: 0.9830 - val_loss: 0.3772 - val_accuracy: 0.9070\n",
      "Epoch 156/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.1307 - accuracy: 0.9737 - val_loss: 0.3054 - val_accuracy: 0.9302\n",
      "Epoch 157/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0874 - accuracy: 0.9892 - val_loss: 0.3243 - val_accuracy: 0.9256\n",
      "Epoch 158/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0871 - accuracy: 0.9923 - val_loss: 0.3435 - val_accuracy: 0.9256\n",
      "Epoch 159/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0873 - accuracy: 0.9861 - val_loss: 0.3031 - val_accuracy: 0.9442\n",
      "Epoch 160/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0773 - accuracy: 0.9938 - val_loss: 0.2870 - val_accuracy: 0.9395\n",
      "Epoch 161/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0748 - accuracy: 0.9923 - val_loss: 0.3240 - val_accuracy: 0.9256\n",
      "Epoch 162/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0865 - accuracy: 0.9892 - val_loss: 0.3249 - val_accuracy: 0.9209\n",
      "Epoch 163/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0826 - accuracy: 0.9923 - val_loss: 0.3878 - val_accuracy: 0.9116\n",
      "Epoch 164/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0757 - accuracy: 0.9923 - val_loss: 0.3211 - val_accuracy: 0.9302\n",
      "Epoch 165/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0857 - accuracy: 0.9923 - val_loss: 0.2950 - val_accuracy: 0.9349\n",
      "Epoch 166/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0658 - accuracy: 0.9954 - val_loss: 0.3202 - val_accuracy: 0.9302\n",
      "Epoch 167/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0772 - accuracy: 0.9923 - val_loss: 0.3047 - val_accuracy: 0.9349\n",
      "Epoch 168/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0742 - accuracy: 0.9907 - val_loss: 0.3214 - val_accuracy: 0.9302\n",
      "Epoch 169/200\n",
      "41/41 [==============================] - 1s 29ms/step - loss: 0.0834 - accuracy: 0.9923 - val_loss: 0.3388 - val_accuracy: 0.9349\n",
      "Epoch 170/200\n",
      "41/41 [==============================] - 2s 54ms/step - loss: 0.0855 - accuracy: 0.9907 - val_loss: 0.3926 - val_accuracy: 0.9209\n",
      "Epoch 171/200\n",
      "41/41 [==============================] - 1s 36ms/step - loss: 0.0937 - accuracy: 0.9845 - val_loss: 0.4020 - val_accuracy: 0.9163\n",
      "Epoch 172/200\n",
      "41/41 [==============================] - 2s 39ms/step - loss: 0.0743 - accuracy: 0.9907 - val_loss: 0.3703 - val_accuracy: 0.9395\n",
      "Epoch 173/200\n",
      "41/41 [==============================] - 2s 37ms/step - loss: 0.0923 - accuracy: 0.9923 - val_loss: 0.3772 - val_accuracy: 0.9302\n",
      "Epoch 174/200\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 0.0895 - accuracy: 0.9861 - val_loss: 0.3376 - val_accuracy: 0.9302\n",
      "Epoch 175/200\n",
      "41/41 [==============================] - 1s 34ms/step - loss: 0.0803 - accuracy: 0.9923 - val_loss: 0.3450 - val_accuracy: 0.9302\n",
      "Epoch 176/200\n",
      "41/41 [==============================] - 1s 35ms/step - loss: 0.0843 - accuracy: 0.9845 - val_loss: 0.3349 - val_accuracy: 0.9395\n",
      "Epoch 177/200\n",
      "41/41 [==============================] - 1s 33ms/step - loss: 0.0659 - accuracy: 0.9969 - val_loss: 0.3178 - val_accuracy: 0.9395\n",
      "Epoch 178/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0732 - accuracy: 0.9938 - val_loss: 0.2857 - val_accuracy: 0.9442\n",
      "Epoch 179/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0641 - accuracy: 0.9969 - val_loss: 0.2756 - val_accuracy: 0.9349\n",
      "Epoch 180/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0795 - accuracy: 0.9892 - val_loss: 0.3441 - val_accuracy: 0.9256\n",
      "Epoch 181/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0867 - accuracy: 0.9845 - val_loss: 0.3448 - val_accuracy: 0.9349\n",
      "Epoch 182/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0742 - accuracy: 0.9923 - val_loss: 0.3580 - val_accuracy: 0.9349\n",
      "Epoch 183/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0957 - accuracy: 0.9830 - val_loss: 0.3335 - val_accuracy: 0.9302\n",
      "Epoch 184/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0749 - accuracy: 0.9923 - val_loss: 0.3578 - val_accuracy: 0.9349\n",
      "Epoch 185/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0687 - accuracy: 0.9954 - val_loss: 0.3227 - val_accuracy: 0.9395\n",
      "Epoch 186/200\n",
      "41/41 [==============================] - 1s 28ms/step - loss: 0.0694 - accuracy: 0.9969 - val_loss: 0.3331 - val_accuracy: 0.9302\n",
      "Epoch 187/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0696 - accuracy: 0.9938 - val_loss: 0.3359 - val_accuracy: 0.9302\n",
      "Epoch 188/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0689 - accuracy: 0.9954 - val_loss: 0.3563 - val_accuracy: 0.9256\n",
      "Epoch 189/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0856 - accuracy: 0.9861 - val_loss: 0.3758 - val_accuracy: 0.9209\n",
      "Epoch 190/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0832 - accuracy: 0.9892 - val_loss: 0.3607 - val_accuracy: 0.9349\n",
      "Epoch 191/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0815 - accuracy: 0.9938 - val_loss: 0.3181 - val_accuracy: 0.9395\n",
      "Epoch 192/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0653 - accuracy: 0.9954 - val_loss: 0.2977 - val_accuracy: 0.9349\n",
      "Epoch 193/200\n",
      "41/41 [==============================] - 1s 24ms/step - loss: 0.0683 - accuracy: 0.9938 - val_loss: 0.3265 - val_accuracy: 0.9395\n",
      "Epoch 194/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0771 - accuracy: 0.9923 - val_loss: 0.3325 - val_accuracy: 0.9349\n",
      "Epoch 195/200\n",
      "41/41 [==============================] - 1s 25ms/step - loss: 0.0704 - accuracy: 0.9938 - val_loss: 0.3319 - val_accuracy: 0.9256\n",
      "Epoch 196/200\n",
      "41/41 [==============================] - 2s 38ms/step - loss: 0.0673 - accuracy: 0.9938 - val_loss: 0.2905 - val_accuracy: 0.9395\n",
      "Epoch 197/200\n",
      "41/41 [==============================] - 1s 30ms/step - loss: 0.0610 - accuracy: 0.9985 - val_loss: 0.2935 - val_accuracy: 0.9395\n",
      "Epoch 198/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0728 - accuracy: 0.9938 - val_loss: 0.3148 - val_accuracy: 0.9395\n",
      "Epoch 199/200\n",
      "41/41 [==============================] - 1s 27ms/step - loss: 0.0745 - accuracy: 0.9938 - val_loss: 0.3275 - val_accuracy: 0.9302\n",
      "Epoch 200/200\n",
      "41/41 [==============================] - 1s 26ms/step - loss: 0.0741 - accuracy: 0.9923 - val_loss: 0.2947 - val_accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dropout, Input, Conv1D, MaxPooling1D,\n",
    "    Flatten, Dense, Activation, TimeDistributed, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "def cnn(x):\n",
    "    #print(x.shape)\n",
    "    #x = Reshape((25, 20,10))(x)  \n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=9, padding='same', kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(MaxPooling1D(pool_size=8, strides=2))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=5, padding=\"same\", kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=3, padding=\"same\", kernel_initializer=\"he_normal\", strides=2, kernel_regularizer=l2(1e-04)))(x)\n",
    "    x = TimeDistributed(BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None))(x)\n",
    "    x = TimeDistributed(Activation('tanh'))(x)\n",
    "    x = TimeDistributed(Dropout(0.2093))(x)\n",
    "    x = TimeDistributed(Dropout(0.5))(x)\n",
    "    x = TimeDistributed(Activation('relu'))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    return x\n",
    "def Bi_LSTMModel(input_shape,x):\n",
    "    #model = Sequential()\n",
    "    # Hidden dimensions\n",
    "    hidden_dim = 200\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    x = Bidirectional(LSTM(hidden_dim, return_sequences=True), input_shape=input_shape)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    x = Bidirectional(LSTM(hidden_dim, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    print(x.shape)\n",
    "    print(11)\n",
    "    #x = Dropout(0.2093)(x)\n",
    "    x = Flatten()(x)\n",
    "    # ( ,10000)\n",
    "    return x\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dropout, Input, Conv1D, MaxPooling1D,\n",
    "    Flatten, Dense, Activation, TimeDistributed, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Define the teacher model\n",
    "def create_teacher_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = cnn(x)  # Use the cnn function from your code\n",
    "    x = Bi_LSTMModel(x.shape[1:], x)  # Use the Bi_LSTMModel function from your code\n",
    "    x = Dense(512, activation='tanh')(x)\n",
    "    x = BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    teacher_model = Model(inputs=inputs, outputs=output_layer)\n",
    "    return teacher_model\n",
    "\n",
    "# Define the student model (smaller model)\n",
    "def create_student_model(input_shape, num_classes):\n",
    "    # Define an additional input for teacher model's predictions\n",
    "    teacher_predictions = Input(shape=(num_classes,))\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = cnn(x)  # Use the cnn function from your code\n",
    "    x = Bi_LSTMModel(x.shape[1:], x)  # Use the Bi_LSTMModel function from your code\n",
    "    x = Dense(256, activation='tanh')(x)  # Smaller hidden layer\n",
    "    x = BatchNormalization(epsilon=1e-06, momentum=0.95, weights=None)(x)\n",
    "    \n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    student_model = Model(inputs=[inputs, teacher_predictions], outputs=output_layer)\n",
    "    return student_model\n",
    "\n",
    "\n",
    "# Create teacher and student models\n",
    "num_classes = 6\n",
    "teacher_model = create_teacher_model((30, 50, 8), num_classes)\n",
    "student_model = create_student_model((30, 50, 8), num_classes)\n",
    "\n",
    "# Define the knowledge distillation loss\n",
    "temperature = 5.0  # You can adjust the temperature\n",
    "\n",
    "# Define the learning rate schedule\n",
    "initial_learning_rate = 1e-3\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "# Compile the teacher model\n",
    "teacher_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule,\n",
    "                                                         beta_1=0.9,\n",
    "                                                         beta_2=0.999,\n",
    "                                                         amsgrad=False),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the teacher model\n",
    "teacher_model.fit(x_train, y_train_onehot, epochs=200, batch_size=16, validation_data=(x_test, y_test_onehot))\n",
    "# Compile the student model with the learning rate schedule and knowledge distillation loss\n",
    "student_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule,\n",
    "                                                         beta_1=0.9,\n",
    "                                                         beta_2=0.999,\n",
    "                                                         amsgrad=False),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the student model using knowledge distillation\n",
    "history = student_model.fit([x_train, teacher_model.predict(x_train)],\n",
    "                            y_train_onehot,\n",
    "                            epochs=200,\n",
    "                            batch_size=16,\n",
    "                            validation_data=([x_test, teacher_model.predict(x_test)], y_test_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f424625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T08:39:58.423350Z",
     "iopub.status.busy": "2023-10-11T08:39:58.423003Z",
     "iopub.status.idle": "2023-10-11T08:40:03.941380Z",
     "shell.execute_reply": "2023-10-11T08:40:03.940434Z",
     "shell.execute_reply.started": "2023-10-11T08:39:58.423320Z"
    },
    "papermill": {
     "duration": 5.138585,
     "end_time": "2023-10-11T14:57:08.664622",
     "exception": false,
     "start_time": "2023-10-11T14:57:03.526037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa62e855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T14:57:18.565497Z",
     "iopub.status.busy": "2023-10-11T14:57:18.565151Z",
     "iopub.status.idle": "2023-10-11T14:57:18.971914Z",
     "shell.execute_reply": "2023-10-11T14:57:18.970560Z"
    },
    "papermill": {
     "duration": 5.536597,
     "end_time": "2023-10-11T14:57:18.973887",
     "exception": false,
     "start_time": "2023-10-11T14:57:13.437290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2947 - accuracy: 0.9488\n",
      "Student Model - Test Loss: 0.29465410113334656, Test Accuracy: 0.9488372206687927\n"
     ]
    }
   ],
   "source": [
    "student_test_loss, student_test_accuracy = student_model.evaluate([x_test, teacher_model.predict(x_test)], y_test_onehot)\n",
    "print(f\"Student Model - Test Loss: {student_test_loss}, Test Accuracy: {student_test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7143.803497,
   "end_time": "2023-10-11T14:57:27.632058",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-11T12:58:23.828561",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
